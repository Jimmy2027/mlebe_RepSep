\section{Evaluation}
For the quality control of the workflow, we first evaluate the classification process, followed by a benchmark between the Generic and the improved (Masked) workflow.

\subsection{Classification}
%%% Again, background or discussion
Quality control of our classifier is difficult in the sense that it should predict a better mask than the template.
Nevertheless, it is useful to verify whether the output is similar, as it should be.
As a similarity metric between the template mask and the classifier output we have used the Dice score (see \cref{eqDcoef}).
The average Dice score taken on every slice of the test data set is $D_{coef}= $ \py{boilerplate.print_dice()} $\sim 1$, indicating that classifier output has only minor changes in comparison with the template.

\begin{sansmath}
\py{pytex_fig('scripts/classifier/plt_testset_examples.py',
        conf='article/wide.conf',
        label='testset_ex',
        caption='
                \\textbf{The Classifier predicts a similar mask to the ground truth.}
                Randomly picked plots from the test set illustrate the predictions of the classifier.
                The first row presents the input image, the second the ground truth and the third row shows the predictions of the classifier.
                ',
        multicol=True,
        )}
\end{sansmath}

\subsection{Workflow}
We use an established palette of workflow evaluation metrics --- inspecting volume and smoothness conservation, as well as downstream effects on basic functional analysis \cite{ioanas_optimized_2019} --- to benchmark the novel SAMRI Masked workflow against the SAMRI Generic workflow.
%%% Introduce RMSE bootstrapping here, as you will need it for both VCF and SCF.
In order to provide a statistical evaluation of the quality of registration, we evaluate a bootstrapped distribution of the respective root mean squared error (RMSE) to the optimal value of 1 for volume conservation and smoothness conservation.
\subsection{Volume Conservation}

\begin{sansmath}
\py{pytex_subfigs(
        [
                {'script':'scripts/vcc_violin.py', 'label':'vccv','conf':'article/1col.conf', 'options_pre':'{.48\\textwidth}',
                        'options_pre_caption':'\\vspace{-1.5em}\\',
                        'options_post':'\\vspace{1em}',
                        'caption':'Comparison across workflows and functional contrasts.'
                        ,},
                {'script':'scripts/scf_violin_contrasts.py', 'label':'sccv','conf':'article/1col.conf', 'options_pre':'{.48\\textwidth}',
                        'options_pre_caption':'\\vspace{-1.5em}\\',
                        'options_post':'\\vspace{1em}',
                        'caption':'Comparison across workflows and functional contrasts.'
                        ,},
                {'script':'scripts/vc_violin_bootstrap.py', 'label':'vcfb','conf':'article/1col.conf', 'options_pre':'{.48\\textwidth}',
                        'options_pre_caption':'\\vspace{-1.5em}\\',
                        'options_post':'\\vspace{1em}',
                        'caption':'Comparison of a bootstrapped distribution of the root mean squared errors to 1, across workflows and functional contrasts.'
                        ,},
                {'script':'scripts/scf_violin_bootstrap.py', 'label':'scfb','conf':'article/1col.conf', 'options_pre':'{.48\\textwidth}',
                        'options_pre_caption':'\\vspace{-1.5em}\\',
                        'options_post':'\\vspace{1em}',
                        'caption':'Comparison of a bootstrapped distribution of the root mean squared errors to 1, across workflows and functional contrasts.'
                        ,},
                ],
        caption='\\textbf{Both the SAMRI Generic and the Masked workflow optimally and reliably conserve volume and smoothness, the latter showing values that are closely distributed to 1.}
        Plots showing the distribution of two target metrics in the first row, together with the respective bootstrapped distributions of the RMESs in the second row. Solid lines in the colored distribution densities indicate the sample mean and dashed lines the inner quartiles.
        ',
        label='fig:vc',
        )}
\end{sansmath}

Volume Conservation Factor (VCF) \cite{ioanas_optimized_2019} measures the registration induced deformation of the scanned brain, by computing the ratio of the brain volume before and after preprocessing.
A positive ratio indicates that the brain was stretched to fill the template space, while a negative ratio indicates that non-brain voxels were introduced in the template brain space.
Volume conservation is highest for a VCF equal to 1, indicating that the preprocessing has no influence on the brain volume of the scans.

As seen in \cref{fig:vccv}, we note that in the described dataset VCF is sensitive to the workflow
(\py{boilerplate.fstatistic('Processing', condensed=True)}),
but not the interaction of the workflow with the contrast (\py{boilerplate.fstatistic('Processing:Contrast', condensed=True)}).
The performance of the Generic SAMRI workflow is different from that of Generic*, yielding a two-tailed p-value of \py{pytex_printonly('scripts/vc_t.py')}.
With respect to the data break-up by contrast (CBV versus BOLD, \cref{fig:vccv}), we see no notable main effect for the contrast variable
(VCF of \py{boilerplate.corecomparison_factorci('Contrast[T.CBV]')}), nor do we report a notable effect for the contrast-workflow interaction (VCF of \py{boilerplate.corecomparison_factorci('Processing[T.Masked]:Contrast[T.CBV]')}).
%%% Ok, you introduce the VCF and you show the VCF plots primarily, and then you list the stats for RMSE only? You should definitely write out the modelling evaluation for VCF. My recommendation is to write down a paragraph for the VCF evaluation, and then RMSE evaluation, plot-wise you show a composite figure with subfigures for VCF, SCF, and the respective bootstrapped RMSE.

%%% briefly introduce what the RMSE tells you here.
We note that there is a significant variance decrease in all conditions for the Masked workflow
(\py{boilerplate.varianceratio()}-fold).
Further, we note that the root mean squared error ratio favours the Masked workflow
($\mathrm{RMSE_{G*}/RMSE_{G}\simeq} \py{pytex_printonly('scripts/vc_rmser.py')}$).
Evaluating a bootstrapped distribution of the respective Root Mean Squared Errors (RMSE) to the optimal VCF 1, we report that it is sensitive to the
workflow (RMSE of \py{boilerplate.bootstrapped_corecomparison_factorci('Processing[T.Masked]')})
and the contrast-workflow interaction (RMSE of \py{boilerplate.bootstrapped_corecomparison_factorci('Processing[T.Masked]:Contrast[T.CBV]')}).

\subsection{Smoothness Conservation}

%%% Same comments as for VCF

Smoothing is a popular tool employed by many preprocessing functions to increase the signal-to-noise ratio.
Image smoothness comes at the cost of image contrast as well as feature saliency and has been shown to result in inferior anatomical alignment \cite{fmriprep} due to the loss of spatial resolution.
As an indicator of image smothness induced by the workflow, the Smoothness Conservation Factor (SCF) \cite{ioanas_optimized_2019} expresses the ratio between the smoothness of the preprocessed images and the smoothness of the original images.
Smoothess Conservation is highest for a SCF equal to 1, indicating that the preprocessing does not influence image smoothness.

While the performance of the Generic SAMRI workflow is only slightly different from that of the Masked workflow, the root mean squared error ratio favors the Masked workflow ($\mathrm{RMSE_{G*}/RMSE_{G}\simeq} \py{pytex_printonly('scripts/scf_rmser.py')}$).

Descriptively, we observe that neither the Generic nor the Masked workflow introduce a strong smoothing (SCF of \py{boilerplate.factorci('Processing[T.Masked]', df_path='data/smoothness.csv', dependent_variable='Smoothness Conservation Factor')}).

Further, we note that there is a notable variance decrease for the Masked workflow
(\py{boilerplate.varianceratio(df_path='data/smoothness.csv',dependent_variable='Smoothness Conservation Factor', max_len=3)}
-fold).

Given the break-up by contrast shown in \cref{fig:sccv}, we see no effect for the contrast variable
(SCF of \py{boilerplate.corecomparison_factorci('Contrast[T.CBV]', df_path='data/smoothness.csv', dependent_variable='Smoothness Conservation Factor')})
and the contrast-workflow interaction
(SCF of \py{boilerplate.corecomparison_factorci('Processing[T.Masked]:Contrast[T.CBV]', df_path='data/smoothness.csv', dependent_variable='Smoothness Conservation Factor')}).

Evaluating a bootstrapped distribution of the respective Root Mean Squared Errors (RMSE) to 1, we report that the RMSE is sensitive to the
workflow (RMSE of \py{boilerplate.bootstrapped_corecomparison_factorci('Processing[T.Masked]', metric= 'smoothness')})
and the contrast-workflow interaction (RMSE of \py{boilerplate.bootstrapped_corecomparison_factorci('Processing[T.Masked]:Contrast[T.CBV]', metric= 'smoothness')}).

\subsection{Functional Analysis}

%%% Same comments as for VCF, these three sections can basically be copy-pasted in as far as the sentence structure is concerned.
Functional Analysis expresses the significance detected across all voxels of a scan by computing the Mean Significance (MS) \cite{ioanas_optimized_2019}.

We observe that the Masked level of the workflow variable does not introduce a notable significance loss
(MS of \py{boilerplate.factorci('Processing[T.Masked]', df_path='data/functional_significance.csv', dependent_variable='Mean Significance')}).
Furthermore, we note a slight variance decrease in all conditions for the Masked workflow
(\py{boilerplate.varianceratio(df_path='data/functional_significance.csv', dependent_variable='Mean Significance')}-fold).

With respect to the data break-up by contrast (\cref{fig:mscv}), we see no notable main effect for the contrast variable
(MS of \py{boilerplate.corecomparison_factorci('Contrast[T.CBV]', df_path='data/functional_significance.csv', dependent_variable='Mean Significance')}).
%and no notable effect for the contrast-template interaction
%(MS of \py{boilerplate.corecomparison_factorci('Processing[T.Legacy]:Contrast[T.CBV]', df_path='data/functional_significance.csv', dependent_variable='Mean Significance')}).

%Functional analysis effects can further be inspected by visualizing the statistic maps.
%Second-level t-statistic maps depicting the CBV and BOLD omnibus contrasts (common to all subjects and sessions) provide a succinct overview capturing both amplitude and directionality of the signal (\cref{fig:m}).
%%While the most salient feature of this figure is the qualitative distribution difference between CBV and BOLD scans, we note that this is to be expected given the different nature of the processes, and is wholly orthogonal to the question of registration.
%The differential coverage is crucial to the examination of registration quality and its effects on functional read-outs.
%We note that processing with the Generic* workflow (\cref{fig:mllc,fig:mllb}), does not induce issues with statistic coverage alignment and overflow.

\subsection{Variance Analysis}

\begin{sansmath}
\py{pytex_fig('scripts/variance_catplot.py',
        conf='article/varplot.conf',
        label='var',
        caption='
                \\textbf{Both the Generic and the Masked workflow minimize trial-to-trial variability while conserving subject-wise variability.}
                Swarmplots of three metric scores illustrate similarity of preprocessed images for the two corresponding workflow templates, plotted across subjects (separated into x-axis bins) and sessions (individual points in each x-axis bin), for the CBV contrast.
                ',
        multicol=True,
        )}
\end{sansmath}

As an additional metric for the comparison between workflows, we evaluate if physiological meaningfull variability is retained across repeated measurements.
It is based on the assumption that adult mouse brains retain size, shape, and implant position in the absence of intervention, throughout the 8 week study period \cite{ioanas_optimized_2019}.
Examining the similarity between the template and preprocessed scans, session-wise variability should be smaller than subject-wise variability.
This comparison is performed using a type 3 ANOVA, modeling both the subject and the session variables.
For this assessment three metrics are used, with maximal sensitivity to different features:
Neighborhood Cross Correlation (CC, sensitive to localized correlation),
Global Correlation (GC, sensitive to whole-image correlation),
and Mutual Information (MI, sensitive to whole-image information similarity).

\Cref{fig:var} renders the similarity metric scores for both the SAMRI Generic and Masked workflows.
Both, the Generic and the Masked workflow produce results which show a higher F-statistic for the subject than for the session variable.
For the Masked workflow, F-statistics show:
CC (subject: \py{boilerplate.variance_test('C(Subject)','Masked','CC', condensed=True)}, session: \py{boilerplate.variance_test('C(Session)','Masked','CC', condensed=True)}),
GC (subject: \py{boilerplate.variance_test('C(Subject)','Masked','GC', condensed=True)}, session: \py{boilerplate.variance_test('C(Session)','Masked','GC', condensed=True)}),
and MI (subject: \py{boilerplate.variance_test('C(Subject)','Masked','MI', condensed=True)}, session: \py{boilerplate.variance_test('C(Session)','Masked','MI', condensed=True)}).

For the Generic SAMRI workflow, resulting data F-statistics show:
CC (subject: \py{boilerplate.variance_test('C(Subject)','Generic','CC', condensed=True)}, session: \py{boilerplate.variance_test('C(Session)','Generic','CC', condensed=True)}),
GC (subject: \py{boilerplate.variance_test('C(Subject)','Generic','GC', condensed=True)}, session: \py{boilerplate.variance_test('C(Session)','Generic','GC', condensed=True)}),
and MI (subject: \py{boilerplate.variance_test('C(Subject)','Generic','MI', condensed=True)}, session: \py{boilerplate.variance_test('C(Session)','Generic','MI', condensed=True)}).
