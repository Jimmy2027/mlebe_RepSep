\section{Evaluation}

%The problem with evaluating preprocessing pipelines is, that we lack ground truth.
%Therefore any approach learning is potentially prone to overfitting.
We evaluate the quality of the registration both in terms of spatial features, as well as in terms of its repercussion on higher-level functional analysis.
%with our novel workflow or with the Here we derive two novel metrics for assessing the quality of the registration, which were not used by engineering the new workflow nor used in the optimisation procedure. 

A main challenge of QC with regard to spatial features is that a perfect mapping to the template is undefined.
Similarity metrics are ill-suited for QC because they are used internally by registration functions, whose main feature it is, that they maximize them.
Indeed an extreme maximization, especially via nonlinear transformations, results in a distortion of the image, which should be penalized in QC, but in light of image similarity scores, is represented as better performance.
Additionally, similarity metrics are not independent, so this issue cannot be circumvented by maximizing a subset of metrics and performing QC in via the remainder.
We thus develop three alternative evaluation metrics: volume conservation, functional analysis, and variance analysis.

\subsection{Volume Conservation}

We have developed a simple, fast, and widely applicable metric to measure distortion introduced by preprocessing workflows.
Volume conservation is based on the assumption that the total volume of the scanned segment of the brain should remain approximately identical after registration.
A volume increase may indicate that the brain was stretched to fill in template brain space not covered by the scan, while a volume decrease might indicate that non-brain voxels were introduced into the template brain space.

For the current implementation we define brain volume as estimated by the 66\textsuperscript{th} percentile of the unregistered scan.
The arbitrary unit equivalent of this percentile threshold is recorded for each scan and applied to all registration workflow results for that particular scan, to obtain transformed brain volume estimates.
In order to mitigate possible differences arising from template size, we perform a multivariate analysis of both template and workflow.
In order to best analyze volume conservation, a Volume Change Factor (VCF) is computed for each processed scan, whereby volume conservation is highest for a VCF equal to 1.

% This metric provides distortion checking rather than goodness-of-fit qantification, which is, as previously described, difficult to do in a lean automated fashion.

\begin{sansmath}
\py{pytex_subfigs(
        [
                {'script':'scripts/vc_violin.py', 'label':'vcv', 'conf':'article/1col.conf', 'options_pre':'{.48\\textwidth}',
			'caption':'Comparison across workflows and target templates, considering both BOLD and CBV both functional contrasts.'
                        ,},
                {'script':'scripts/vcc_violin.py', 'label':'vccv','conf':'article/1col.conf', 'options_pre':'{.48\\textwidth}',
                        'caption':'Comparison across workflows and functional contrasts, considering only matching template-workflow combinations.'
                        ,},
                ],
        caption='Volume change relative to the original scan volume. Coloured patch width estimates distribution density, while continuous markers indicate the sample mean and dashed markers indicate the inner quartiles.',
        label='fig:vc',)}
\end{sansmath}

As seen in \cref{fig:vcv}, we note that the Volume Change Factor (VCF) metric is sensitive to both
the processing workflow (\py{boilerplate.fstatistic('Processing', condensed=True)}),
the template (\py{boilerplate.fstatistic('Template', condensed=True)}),
and interaction thereof (\py{boilerplate.fstatistic('Processing:Template', condensed=True)}).

Testing the core hypothesis of the comparison ---
whether the Generic SAMRI workflow (with the Generic template) performs significantly different than the Legacy workflow (with the Legacy template) ---
we note that it does
(two-tailed p-value of \py{pytex_printonly('scripts/vc_t.py')}).
Additionally we note a root mean squared error ratio strongly favouring the Generic workflow
($\mathrm{RMSE_{L}/RMSE_{G}\simeq} \py{pytex_printonly('scripts/vc_rmser.py')}$).

Descriptively, we observe that the effect with the greatest magnitude is that of the template variable, with its Legacy level introducing a notable volume loss
(VCF of \py{boilerplate.vc_factorci('Template[T.Legacy]')}).
Further, we note that there is a variance increase in all conditions for the Legacy processing workflow
(\py{boilerplate.varianceratio(template='Legacy')}-fold given the Legacy template, and \py{boilerplate.varianceratio(template='Generic')}-fold given the Generic template).

With respect to the data break-up by contrast (from \cref{fig:vccv}), we see no notable main effect for the contrast variable
(VCF of \py{boilerplate.vcc_factorci('Contrast[T.CBV]')}).
We do, however, report a notable effect for the contrast-template interaction, with the Legacy workflow and CBV contrast interaction level introducing a volume loss
(VCF of \py{boilerplate.vcc_factorci('Processing[T.Legacy]:Contrast[T.CBV]')}).

\subsection{Functional Analysis}

Functional analysis in another suitable method to ascertain registration quality, as the metric being maximized in the registration process is not the same metric used for QC.
This method is however primarily (and exceptionally) suited to demonstrate workflow relevance to higher-level applications, and less suited for wide-spread QC (as it is the most computationally intensive and only applicable to a subset of all mouse MRI data).

\begin{center}
        \textcolor{lg}{[...]}
\end{center}


% Move the color switch to the start of the remaining draft segment.
\subsection{Variance Analysis}

While the absolute value of image similarity metrics cannot be relied upon for QC, the variance structure of similarity metrics in longitudinal datasets can.
The rationale of analysing similarity metric variance is that in healthy adult mice, there is no significant change in brain structure over time, but there are significant differences in individual anatomy.
This proposition is further strengthened in our dataset, as each animal has a slightly different but temporally stable implant placement. 
The corollary of this statement in terms of value distributions, is that the more variance is reduced across sessions without being reduced across subjects, the more stable a workflow is and the less likely it is for its performance to be derived from over-fitting.

\color{lg}
We use this metric to optimize our registration parameters, as it is uniquely suites to our dataset (as opposed to to other implant-less data sets), and allows us to leverage it to a maximum use for the community, while keeping other less intricate and unrelated metrics usable for transferable QC for external datasets.


\[ CC(x) = \frac{\sum_i{(x)}}{\sum_i{(x)}} \]

%\py{pytex_fig('scripts/registration_qc.py', conf='article/varplot.conf', label='varplot', caption='Variance for different preprocessing pipelines')}

To assess the quality of the pipeline we evaluated the registration performance for different metrices (Crosscorrelation (CC), Mutual Information (MI), Mean Squared Difference (MSQ)) for individual sessions and subjects on a representatitve dataset.
We define an assessment for registration quality based on the assumption, that for increased registration quality the variance of a similariy measure between the subject and the template should converge towards 0.
This definition is based on the assumption that biological deformations of the brain across sessions should be negligible (Ref???!?!).
Hence we calculate the variance over different similiarity metrics for each subject across sessions.
We average for each workflow the results across subjects.
We find that our new preprocessing pipeline has significantly less variance than the legacy workflow, while the optimised pipeline has even further decreased variance.
