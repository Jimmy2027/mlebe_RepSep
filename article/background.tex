\section{Background}
In order to make meaningful comparisons across subjects inside a study, it is imperative that the images lie in a standard reference frame.
Because of positioning imprecision and anatomical animal variations, this is not the case for the original MR acquired images.
To solve this issue, the images need to be projected into the reference frame via registration \cite{maintz_overview_nodate, sotiras_deformable_2013}. 
Intensities outside the brain region of a mouse MR image present high variations and bias the registration process.
As a remedy, it would be useful to extract the region of interest and perform the registration on it.
For this purpose, we propose a machine learning enabled brain extraction in an additional node to the workflow presented by Ioanas et al. \cite{ioanas_optimized_2019}.
The additional node creates a mask of the brain region with segmentation using a classifier.
The image is then masked such that only the region of interest remains.


\subsection{Convolutional Neural Networks} \label{sec:Convolutional Neural Networks}
In recent years it has been shown that convolutional neural network give the best results for semantic image segmentation in terms of precision and flexibility \cite{geng_survey_2018} \cite{ronneberger_u-net:_2015}.
Training a convolutional neural network into a classifier is a supervised method, meaning that the model needs to learn its parameters based on observations of data.

The training data set of a classifier is as important as the architecture of the model itself.
To improve general-purpose application, training examples need to be drawn from a usually unknown probability distribution, that is expected to be representative of the space of occurrences.
We define the space of occurrences as the space of which the data of interest is drawn from.
In our case this consists of all the different mouse brain MRI data sets coming from multiple experiments, with their corresponding labels. 
Ideally experiment setups are uniform and the resulting data does not differ much, but small variations in the experiment setup and animal size are unavoidable.
Based on an approximation of the occurrence space, the network has to build a general model that enables it to extrapolate and produce sufficiently accurate predictions in new cases.
Manually creating annotations as required to train a deep-learning classifier for high-resolution data is often infeasible, since it requires manual expert segmentation of vast amounts of slices.

Here we take as data set, images that were registered through the SAMRI workflow into a reference frame defined by the Toronto Hospital for Sick Children Mouse Imaging Center. %TODO:cite(15 in old bib)
A mask that was made in the same reference frame was used as ground truth.
Because the registration process is not perfect, the mask does not always align perfectly with the brain region of every slice.
While our purpose was to create a workflow that generates better masks than the one from the template space, we showed that the latter could be used as training data for the deep-learning model, by applying small changes to them.