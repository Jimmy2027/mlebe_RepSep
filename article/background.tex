\section{Background}
\label{sec:bg}

In order to make any generalizable statements regarding brain function and organization, an equivalence between brain areas across individuals needs to be established.
This is most commonly done by spatial (rigid, affine, and non-linear) transformation of all brain maps in a study to a population or standard reference template.
This process, called registration, is consequently performed as part of any neuroimaging workflow attempting to produce results which are both spatially resolved and generalizable across the population.

The computations required for registration are commonly performed at the very onset of the preprocessing workflow,
though --- depending on the workflow --- the actual image manipulation may only take place much later, once inter-subject comparison becomes needed.
% [[[paper which does this and says that it minimizes interpolation]]].
As a consequence of this marginal positioning in the preprocessing sequence, as well as its general independence from experimental designs and hypotheses, registration is often relegated to default values and exempt from rigorous design efforts and QC.

Registration QC is a notable issue for human as well as mouse brain imaging;
and is not limited as much by a lack of reporting functions, as by a lack of reporting metrics which can easily be communicated for a population.
Human brain imaging uniquely benefits from high-level functions (e.g.  \textcolor{mg}{\texttt{flirt}} and  \textcolor{mg}{\texttt{fnirt}} from the FSL package\cite{fsl}, or \textcolor{mg}{\texttt{antsIntroduction.sh}} from the ANTs package\cite{ants}), optimized for the size and spatial features of the human brain.
The availability and widespread use of such functions mitigates issues which would otherwise arise from a lack of QC.
In mouse brain imaging, however, registration is frequently performed using the selfsame high-level functions from human brain imaging which are rendered usable for mouse brain data by adjusting the nature of the data to fit the priors and optimized parameters of the functions (rather than vice-versa).

This general approach represents a notable hurdle for the methodological improvement of mouse brain imaging.
Furthermore, such solutions are intended as “fast fixes”, and are not thoroughly documented anywhere in the field.
We thus explicitly describe current practices, in an effort to not only propose better solutions, but do so in a falsifiable manner which provides adequate reference for both the novel and the legacy methods.

\subsection{Manipulations}
The foremost data manipulation procedure in present-day mouse MRI is the adjustment of voxel dimensions.
These dimensions are represented in the Neuroimaging Informatics Technology Initiative format (NIfTI) header \cite{nifti} by affine transformation parameters --- which map data matrix cordinates to geometrically meaningful spatial coordinates.
Manipulations of the affine parameters are performed in order to make the data represent not the physiological mouse brain dimensions, but volumes corresponding to what human-optimized brain extraction, bias correction, and registration interfaces expect (commonly this constitutes a 10-fold increase in each spatial dimension).

Another notable data manipulation procedure consists in adjusting the data matrix content itself, so that human-prior based brain extraction will produce acceptable results.
While conceptually superior solutions adapting parameters and priors to animal data are available \cite{rbet,Oguz2014} and might remove the need for data adaptation at this step, rudimentary solutions remain popular.
Many consist of applying an empirically determined percentile threshold to clear non-brain or distal brain tissue by intensity, and to leave a more spherical brain for the human masking function to operate on.
Notably, both the function adaptations for animal data and the animal data matrix adaptations for use with human brain extraction functions are known to wholly or partly remove the olfactory bulbs --- which is why sometimes the choice is made to instead simply forego brain extraction.

Often, the orientation of the scan is seen as problematic, and consequently deleted.
This consists in resetting the S-Form affine from the NIfTI header to zeroes, and is intended to mitigate a data orientation produced by the scanner which is incorrect with respect to the target template.
While it is true that the scanner affine reported for mouse data may be nonstandard (the confusion is two-fold: mice lie prone with the coronal plane progressing axially whereas higher primates lie supine with the horizontal plane progressing axially), affines of mouse brain templates may be nonstandard as well.
A related manipulation is dimension swapping, which changes the order of the NIfTI data matirx rather than the affine.
Occasionally, correct or automatically redressable affine parameters are thus deleted and data is reordered beyond easy recovery, in order to correspond to a malformed template.

\begin{figure*}[h!]
	\begin{subfigure}{\textwidth}
		\centering
		\includedot[width=\textwidth]{data/metadata}
		\vspace{-2.5em}
		\caption{
			Flowchart depicting consistent metadata handling. This minimizes operator interaction and ensures that all information accessible to the data format (e.g. NIfTI + BIDS) is correctly encapsulated at every step, and correctly interpretable by researchers familiar with the openly documented standards.
			}
		\label{fig:mdg}
	\end{subfigure}
	\begin{subfigure}{\textwidth}
		\centering
		\includedot[width=\textwidth]{data/metadata_bad}
		\vspace{-2.5em}
		\caption{
			Flowchart depicting ad hoc metadata substitution. This introduces additional operator interaction steps (colored brown), and renders the metadata encapsulated in standardized formats ambiguous (coloured red), and less well interpretable to researchers unfamiliar with the specific ad hoc convention.
			}
		\label{fig:mdb}
	\end{subfigure}
	\caption{
		Simplified fMRI data flowcharts, depicting individual processing steps, highlighting the possibility of sharing data at every step during analysis, and contrasting consistent and ad-hoc metadata management.
		}
	\label{fig:md}
\end{figure*}

\subsection{Templates}
As the above eminently demonstrates, the template is a key component of a registration workflow.
Templates used for mouse brain MRI registration are highly heterogeneous, and include histological, as well as ex vivo MRI templates, scanned either inside the intact skull or after physical brain extraction.

Histological templates benefit from higher resolution and access to molecular imaging data in the same coordinate space.
Such templates are not produced in volumetric sampling analogous to MRI, and are often not assigned a meaningful affine after conversion to NIfTI.
Histological contrast may only poorly correlate with any MR contrast, making registration less reliable, or necessitating the use of similarity metrics which impose additional restrictions.
Not least of all, histological templates may be severely deformed (and may lack distal parts of the brain such as the olfactory bulbs) due to the extraction and sampling process.
Consequently, data registered to them may be particularly difficult to use for navigation in the intact mouse brain, e.g. during data acquisition or stereotactic surgery.

Ex-vivo templates based on extracted brains share most of the deformation issues present in histological templates;
they are, however, available in MR contrasts making registration far easier.
They suffer from a lower resolution, and need to have any histological data relevant for downstream analysis first registered to them.
Ex-vivo templates based on intact mouse heads provide both MR contrast and brains largely free of deformation and supporting whole brain registration.

\subsection{Challenges}
It thus becomes obvious that the foremost challenges in mouse MRI registration consist in minimizing workarounds and reliance on high-level interfaces with inappropriate optimizations, as well as in the reduction of the number of standard space templates.
Information loss (e.g. pertaining to both the affine and the data matrix) during preprocessing is another notable issue, since the loss of data at the onset of a neouroimaging workflow will persist in all downstream steps and preclude numerous modes of analysis (as depicted in \cref{fig:md}).

