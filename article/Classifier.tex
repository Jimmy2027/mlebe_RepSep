\section{The Improved Workflow}

Intensities outside the brain region of a mouse MR image present high variations and bias the registration process.
This can lead to stretching or skewing of the brain during the registration process in order to fit unwanted intensities inside the template brain region.
As a remedy, we extract the brain volume from the images and compute the registration transformation on an image specific region of interest.
For this purpose, we propose a machine learning enabled brain extraction in an additional node to the Generic workflow presented by Ioanas et al. in \cite{ioanas_optimized_2019}.
It creates a mask of the brain region using a classifier, that is then used to extract the region of interest.
Two classifiers were trained, one for T2 contrast images and one for BOLD \cite{bold} and CBV \cite{cbv} contrasts.
The brain extraction nodes of the workflow return both the masked input and the binary mask.
The latter is used to concentrate computing effort on a region of interest in preprocessing functions while the extracted brain volume is used to compute the registration transformation.

\section{The Classifier} \label{sec:Convolutional Neural Networks}
Classifiying each pixel with "brain" and "not brain" for the brain region extraction is done via a deep learning method.
In recent years it has been shown that convolutional neural network give the best results for semantic image segmentation in terms of precision and flexibility \cite{geng_survey_2018, ronneberger_u-net:_2015}.
Training a neural network into a classifier is a supervised method, meaning that the model needs to learn its parameters based on observations of data.

The training data set of a classifier is as important as the architecture of the model itself.
To improve general-purpose application, training examples need to be drawn from a usually unknown probability distribution, that is expected to be representative of the space of occurrences.
We define the space of occurrences as the space of which the data of interest is drawn from.
In our case this consists of all the different mouse brain MRI data sets coming from multiple experiments, with their corresponding labels.
Ideally experiment setups are uniform and the resulting data does not differ much, but small variations in the experiment setup and animal size are unavoidable.
Based on an approximation of the occurrence space, the network has to build a general model that enables it to extrapolate and produce sufficiently accurate predictions in new cases.
Manually creating annotations as required to train a deep-learning classifier for high-resolution data is often infeasible, since it requires manual expert segmentation of vast amounts of slices.

Here we take as data set, images that were registered through the SAMRI workflow into a reference space defined by the Toronto Hospital for Sick Children Mouse Imaging Center \cite{dsu}.
A mask, defined in the same reference space is used as ground truth.

The registration process is good but not perfect, which is why the mask does not always align perfectly with the brain region of every slice.
While our purpose was to create a workflow that generates better masks than the one from the template space, we show that the latter can be used as training data for the deep-learning model, by applying small changes to them.