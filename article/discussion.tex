\section{Discussion}

We conclude from the evaluation that the workflow and template design presented herein offer significant advantages in terms of reducing coverage overestimation, and effective loss of resolution.
This is most clearly evident from the Volume Conservation results (\cref{fig:vc}), Variance Analysis (\cref{fig:var}) and Smoothness Conservation (\cref{fig:sc}), where in all cases the joint usage of the SAMRI Generic workflow and Generic template outperform all other combinations of the multivariate analysis.
This spatial robustness is also revealed in a qualitative examination of higher-level functional maps (\cref{fig:m}), where only the combination of the Generic workflow and the Generic template provides accurate coverage for both BOLD and CBV modalities.
These benefits are provided without compromising statistical power (\cref{fig:ms}), and this also holds for both CBV and BOLD contrasts (\cref{fig:vccv,fig:mscv}).
Additionally, the performance of the Generic processing workflow is more consistent, as shown in notable reductions of the standard deviation for both VCS, MS, and SCF (\cref{fig:vcv,fig:msv,fig:scv}).

These features are augmented by design benefits such as added transparency and parameterization of the workflow (which can more easily be inspected and further improved or customized by the end user), veracity of resulting data headers, and spatial coordinates more meaningful for surgery and histology.

% !!! MMa: instead of added transp. and parametrization, I would just write: ... by implementing a fully transparent and parametrized end-to-end python workflow to emphasize more

We acknowledge that our recommendation can only extend as far as favouring the Generic SAMRI workflow as an indivisible unit.
More fine-grained processing steps within the workflow (e.g. the inclusion or exclusion of a skull stripping step) cannot be reliably advocated or dismissed based solely on the holistic evaluation presented here.
Further, we hold that the two workflows discussed represent discrete processing principles and are not arbitrarily mixable (e.g. intensity manipulations go hand in hand with the masking choice, and the structural intermediary goes hand in hand with the registration interface choice).
Thus, in support of \textit{individual} nodes in the processing workflows (\cref{fig:wfg}), we only make theoretical claims.

\subsection{Quality Control}

We note that a major contribution of this work is the introduction of multiple metrics for simple, powerful and robust Quality Control for registration performance (VCF, SCF, and Variance Analysis) and releasing a dataset suitable for such multifaceted benchmarking.
The VCF provides a good quantitative estimate of distortion prevalence, which also becomes salient in qualitative operator inspection (e.g. in \cref{fig:m}).
Similarly, the SCF assesses the degree of spatial resolution loss in a quantitative fashion.
By comparing subject-wise and session-wise variance, the operator can ascertain how much a registration pipeline is potentially overfitting.
Indeed, we believe that these metrics themselves are interesting and could be further optimized (e.g. by developing percentile selection heuristics based on a priori documented data distortions for VCF).

Global statistical power is not --- at least in the range of workflows at hand --- sensitive to registration.
It is thus not a reliable metric for optimization, though regrettably, it may be the most prevalently used if results are only inspected at a higher level --- and thus lead to analysis biasing in favour of a hypothesis.
Demonstrating this is the positive interaction effect of the Legacy workflow level and the CBV contrast for the comparison in \cref{fig:mscv}, in this particular case, optimizing for statistical power alone may give a misleading indication.
We do not discount this measure entirely, however, as it is strongly sensitive to workflow parameter variations which we have excluded for the sake of brevity in this comparison (such as registration interpolation method).

Overall we suggest that a VCF, SCF and Variance based comparison, coupled with visual inspection of a small number of omnibus statistic maps is a feasible and sufficient tool for benchmarking workflows, with MS usable as an additional sanity check.
We recommend reuse of the data herein presented for workflow benchmarking, as it includes (a) multiple sources of variation (contrast, session, subjects), (b) functional activity with broad coverage but spatially distinct features, and (c) significant distortions due to implant properties --- which are appropriate for testing the workflow robustness.
Owing to the RepSeP-compilant executable source code, which reliably reproduces the statistics and figures in this document, our processing and data analysis work not only is fully transparent, but also reusable for further data or further workflows.

\subsection{Conclusion}

The SAMRI Generic workflow and Generic template presented in this article represent a notable leap in mouse brain imaging registration, as attested by an in-depth multivariate comparison of these processing choices with a thoroughly documented Legacy pipeline representing alternative practices.
For the comparison of workflows, we introduced metrics that can be used beyond the scope of this work for Quality Control of registration workflows.
The optimized registration parameters of the Generic workflow can be transferred to other interfaces which feature highly parameterized lower-level interfaces, making our work even more broadly applicable.
The software engineering choices in both the workflow and this article's source code also empower users to better verify, understand, remix, and reuse our work.
Overall we believe that the insights presented and technologies showcased herein will have a significant role in profoundly improving computational mouse brain imaging methodology.
