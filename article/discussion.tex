\section{Discussion}
\subsection{Workflow and Template Recommendation}

We conclude from the evaluation that the workflow and template design presented herein offer significant advantages in terms of reducing coverage overestimation and region misassignment.
This is most clearly evident from the Volume Conservation results (\cref{fig:vc}) where the joint usage of our Generic workflow and our Generic template decisively outperform all other combinations of the multivariate analysis.
The spatial robustness thus evident is also revealed in a qualitative examination of higher-level functional maps (as seen in \cref{fig:m}, where the combination of the Generic workflow using the Generic template provides, unlike all others, accurate coverage across both contrasts).
We note that these benefits are provided entirely without compromising statistical power (\cref{fig:ms}), and that this holds for both CBV and BOLD contrasts (\cref{fig:vccv,fig:mscv}).

Further supporting this recommendation is that these features are augmented by design benefits such as added transparency and parameterization of the workflow (which can more easily be inspected and further improved or customized by the end user), veracity of resulting data headers, and resulting coordinates more meaningful for surgery and histology.

\subsection{Quality Control}

We note that the Volume Change Factor (VCF) is a remarkably simple, powerful, and robust QC tool for registration performance.
It provides a good quantitative estimate of distortion features which are salient in qualitative operator inspection (e.g. \cref{fig:m}).
Indeed, we believe that this metric could itself be further optimized (e.g. by developing percentile selection heuristics based on a priori documented data distortions).

Conversely, we note that global statistical power is not --- at least in the range of workflows at hand --- sensitive to registration.
It is thus not a reliable metric for optimization, though sadly, it may be the most prevalently used if results are only inspected at a higher level.

Overall we suggest that a VCF comparison, coupled with visual inspection of a small number of omnibus statistical maps is a feasible and sufficient tool for benchmarking workflows.
Additionally, we recommend the data herein presented for such a procedure, as it includes (a) multiple sources of variation (contrast, session, subjects), (b) functional activity with broad coverage but spatially distinct features, (c) significant distortions due to implant presence, which are appropriate for testing the robustness of a workflow.
Not least of all, we hope that the RepSeP-compilant executable source code, which reliably reproduces this document, will make it easier not only to fully inspect and understand our results, but also to apply all of our tests to further data or further workflows.

\subsection{Limitations}

We acknowledge that going beyond our omnibus recommendation in favour of the Generic workflow and template, individual processing steps cannot be reliably advocated or dismissed based solely on the holistic evaluation presented herein.
Further, we hold that the two workflows discussed represent discrete processing principles and are not arbitrarily mixable (e.g. intensity manipulations go hand in hand with the masking choice, and the structural intermediary goes hand in hand with the registration interface choice).
Therefore, we make no claims other than theoretical support for \textit{individual} nodes in the processing workflows (\cref{fig:wfg}).

