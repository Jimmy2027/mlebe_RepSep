\section{Discussion}

We conclude from the evaluation that the workflow and template design presented herein offer significant advantages in terms of reducing coverage overestimation and region misassignment.
This is most clearly evident looking at Volume Conservation results (\cref{fig:vc}), Variance Analysis (\cref{fig:variance}) and Smoothness Conversation (\cref{fig:scf}) where the joint usage of the SAMRI Generic workflow and Generic template outperform all other combinations of the multivariate analysis.
This spatial robustness is also revealed in a qualitative examination of higher-level functional maps (\cref{fig:m}) where only the combination of the Generic workflow and the Generic template provides accurate coverage for both BOLD and CBV modalities.
These benefits are provided without compromising statistical power (\cref{fig:ms}), and this also holds for both CBV and BOLD contrasts (\cref{fig:vccv,fig:mscv}).
Additionally, the performance of the Generic processing workflow is more consistent, as shown in notable reductions of the standard deviation for both VCS and MS (\cref{fig:vcv,fig:msv}).

These features are augmented by design benefits such as added transparency and parameterization of the workflow (which can more easily be inspected and further improved or customized by the end user), veracity of resulting data headers, and spatial coordinates more meaningful for surgery and histology.
\begin{comment}
instead of added transp. and parametrization, I would just write: ... by implementing a fully transparent and parametrized end-to-end python workflow to emphasize more
\end{comment}

We acknowledge that our recommendation can only extend as far as favouring the Generic template on one hand and the Generic SAMRI workflow as an indivisible unit on the other.
More fine-grained processing steps within the workflow (e.g. the inclusion or exclusion of a skull stripping step) cannot be reliably advocated or dismissed based solely on the holistic evaluation presented here.
Further, we hold that the two workflows discussed represent discrete processing principles and are not arbitrarily mixable (e.g. intensity manipulations go hand in hand with the masking choice, and the structural intermediary goes hand in hand with the registration interface choice).
Thus, in support of \textit{individual} nodes in the processing workflows (\cref{fig:wfg}), we only make theoretical claims.

\subsection{Quality Control}

We note that a major contribution of this work is the introduction of multiple metrics for simple, powerful and robust Quality Control for registration performance:  Volume Change Factor (VCF), Smoothness Change Factor (SCF), Variance Analysis..
The VCF provides a good quantitative estimate of distortion prevalence, which also becomes salient in qualitative operator inspection (e.g. in \cref{fig:m}). Similarly, the SCF assesses the degree of degradation of spatial resolution in a quantitative fashion. By comparing subject vs. session explained variance, the operator can acertain how much a registration pipeline is potentially overfitting.
Indeed, we believe that these metrics themselves are interesting and could itself be further optimized (e.g. by developing percentile selection heuristics based on a priori documented data distortions).

Global statistical power is not --- at least in the range of workflows at hand --- sensitive to registration.
It is thus not a reliable metric for optimization, though sadly, it may be the most prevalently used if results are only inspected at a higher level.
In isolated cases, even, as shown by the positive interaction effect of the Legacy workflow level and the CBV contrast for the comparison in \cref{fig:mscv}, usage of this metric alone may give a misleading indication.
We would not discount this measure entirely, however, as it is strongly sensitive to workflow variations which we have consciously not included in this comparison (such as registration interpolation method).

Overall we suggest that a VCF, SCF and Variance based comparison, coupled with visual inspection of a small number of omnibus statistic maps is a feasible and sufficient tool for benchmarking workflows, with MS usable as an additional sanity check.
We recommend the data herein presented for workflow benchmarking, as it includes (a) multiple sources of variation (contrast, session, subjects), (b) functional activity with broad coverage but spatially distinct features, (c) significant distortions due to implant properties --- which are appropriate for testing the workflow robustness.
Owing to the RepSeP-compilant executable source code, which reliably reproduces the statistics and figures in this document, our processing and data analysis work not only is fully transparent, but also reusable for further data or further workflows.

\subsection{Conclusion}

The SAMRI Generic workflow and Generic template presented in this article represent a notable leap in mouse brain imaging registration, as attested by an in-depth multivariate comparison of these processing choices with a thoroughly documented Legacy pipeline representing alternative practices.
For the comparison of workflows, we introduced metrics, that can be used outside in a broader manner, outside of the scope of this work for Quality Control of registration workflows.
The optimized registration parameters of the Generic workflow, can be transferred to other interfaces using highly parameterized lower-level interfaces, making our work even more broadly applicable.
The software engineering choices in both the workflow and this article's source code also empower users to better verify, understand, remix, and reuse our work.
Overall we believe that the insights presented and technologies showcased herein will have a significant role in profoundly improving computational mouse brain imaging methodology.
