\subsection{Extra}
The templates used for mouse brain MRI are highly heterogeneous, limiting data integration potential.
Affine “removal” comes to the strong detriment to the resulting neuroimaging data, which persists in all downstream statistics produced from such data.
This is due to the fact that visual representation unavoidably requires an affine transformation (to turn data points into volumes in space), and the deletion of this information makes the spatial representation more rather than less ambiguous.
One common issue which may arise is that software (rightfully) attempts to recreate the affine information.
Such data recovery behaviour is not determined by the NIfTI (or any other) standard, and as such is unpredictable.
An illustration of this issue ls given by the comparison of coordinates in the MRIcroGL and SAMRI (internally using NiLearn) plots of the legacy pipeline results.

While a population template may require less deformation, it only permits within-study comparability, and requires additional interpolation in order to allow region of interest (ROI) delineation or inter-study comparison.
While it is beyond the scope or intent of this study to single out and individually investigate articles by our colleagues, we offer a comparison from our own data and pipelines, illustrating the benefits of context awareness and specific optimizations in animal MRI.
Destructive hacks in particular (such as affine transformation deletion or scaling) preclude both the usage of preprocessed data and of the preprocessing workflow itself in size-sensitive applications, which may include a plethora of diagnostic or preoperative imaging scenarios (e.g. !!!cite StereotaXYZ!!!).

Human MRI research has produced numerous registration toolkits and associated workflow implementations, predominantly accessed via high-level interfaces contain hard-coded parameters optimized for specific human MRI use cases.
Animal MRI commonly makes use of these high-level interfaces, and implements additional hacks to mitigate the nonhuman idiosyncracies of the species being imaged --- instead of optimizing the workflow for the data at hand.
Quality control is commonly performed by operator inspection, making it infrequent, biased, slow, and unreproducible.
In this paper we present a novel workflow using the full flexibility of low-level functions from one of the most popular neuroimaging registration toolkits, and provide an optimized set of parameters for small animal imaging.
Additionally, we present a quality control (QC) workflow, which can automatically assess the registration quality of processed datasets.
We showcase the capabilities of both workflow, by comparing our current registration performance with that of a legacy registration workflow (containing multiple popular hacks - which we specifically critique).


