@ARTICLE{2020SciPy-NMeth,
       author = {{Virtanen}, Pauli and {Gommers}, Ralf and {Oliphant},
         Travis E. and {Haberland}, Matt and {Reddy}, Tyler and
         {Cournapeau}, David and {Burovski}, Evgeni and {Peterson}, Pearu
         and {Weckesser}, Warren and {Bright}, Jonathan and {van der Walt},
         St{\'e}fan J.  and {Brett}, Matthew and {Wilson}, Joshua and
         {Jarrod Millman}, K.  and {Mayorov}, Nikolay and {Nelson}, Andrew
         R.~J. and {Jones}, Eric and {Kern}, Robert and {Larson}, Eric and
         {Carey}, CJ and {Polat}, {\.I}lhan and {Feng}, Yu and {Moore},
         Eric W. and {Vand erPlas}, Jake and {Laxalde}, Denis and
         {Perktold}, Josef and {Cimrman}, Robert and {Henriksen}, Ian and
         {Quintero}, E.~A. and {Harris}, Charles R and {Archibald}, Anne M.
         and {Ribeiro}, Ant{\^o}nio H. and {Pedregosa}, Fabian and
         {van Mulbregt}, Paul and {SciPy 1.0 Contributors}},
        title = "{{SciPy} 1.0: Fundamental Algorithms for Scientific
                  Computing in Python}",
      journal = {Nature Methods},
      year = {2020},
      volume={17},
      pages={261--272},
      adsurl = {https://rdcu.be/b08Wh},
      doi = {https://doi.org/10.1038/s41592-019-0686-2},
}


@software{oktay_ozan-oktayattention-gated-networks_2020,
	title = {ozan-oktay/Attention-Gated-Networks},
	rights = {{MIT} License         ,                 {MIT} License},
	url = {https://github.com/ozan-oktay/Attention-Gated-Networks},
	abstract = {Use of Attention Gates in a Convolutional Neural Network / Medical Image Classification and Segmentation},
	author = {Oktay, Ozan},
	urldate = {2020-07-24},
	date = {2020-07-22},
	note = {original-date: 2018-04-02T21:50:07Z},
	keywords = {attention-gates, attention-model, convolutional-neural-networks, image-classification, image-segmentation}
}

@article{oktay_attention,
	title = {Attention U-Net: Learning Where to Look for the Pancreas},
	abstract = {We propose a novel attention gate ({AG}) model for medical imaging that automatically learns to focus on target structures of varying shapes and sizes. Models trained with {AGs} implicitly learn to suppress irrelevant regions in an input image while highlighting salient features useful for a speciﬁc task. This enables us to eliminate the necessity of using explicit external tissue/organ localisation modules of cascaded convolutional neural networks ({CNNs}). {AGs} can be easily integrated into standard {CNN} architectures such as the U-Net model with minimal computational overhead while increasing the model sensitivity and prediction accuracy. The proposed Attention U-Net architecture is evaluated on two large {CT} abdominal datasets for multi-class image segmentation. Experimental results show that {AGs} consistently improve the prediction performance of U-Net across different datasets and training sizes while preserving computational efﬁciency. The source code for the proposed architecture is publicly available.},
	pages = {10},
	author = {Oktay, Ozan and Schlemper, Jo and Folgoc, Loic Le and Lee, Matthew and Heinrich, Mattias and Misawa, Kazunari and Mori, Kensaku and {McDonagh}, Steven and Hammerla, Nils Y and Kainz, Bernhard and Glocker, Ben and Rueckert, Daniel},
	langid = {english},
	file = {Oktay et al. - Attention U-Net Learning Where to Look for the Pa.pdf:/Users/Hendrik/Zotero/storage/XN75TT43/Oktay et al. - Attention U-Net Learning Where to Look for the Pa.pdf:application/pdf}
}

@article{borsook_role_2006,
	title = {A role for {fMRI} in optimizing {CNS} drug development},
	volume = {5},
	rights = {2006 Nature Publishing Group},
	issn = {1474-1784},
	url = {https://www.nature.com/articles/nrd2027},
	doi = {10.1038/nrd2027},
	abstract = {{fMRI} is a relatively new technology that is now being evaluated for use in drug development. This has generated significant interest from biotech and pharmaceutical companies wishing to decrease the risk of drug development. Borsooket al. examine the potential use of {fMRI} as a tool to integrate drug development and optimize clinical development and later stage clinical trials.},
	pages = {411--425},
	number = {5},
	journaltitle = {Nature Reviews Drug Discovery},
	author = {Borsook, David and Becerra, Lino and Hargreaves, Richard},
	urldate = {2020-05-01},
	date = {2006-05},
	langid = {english},
	note = {Number: 5
Publisher: Nature Publishing Group},
}

@article{friston_dynamic_2003,
	title = {Dynamic causal modelling},
	volume = {19},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811903002027},
	doi = {10.1016/S1053-8119(03)00202-7},
	abstract = {In this paper we present an approach to the identification of nonlinear input–state–output systems. By using a bilinear approximation to the dynamics of interactions among states, the parameters of the implicit causal model reduce to three sets. These comprise (1) parameters that mediate the influence of extrinsic inputs on the states, (2) parameters that mediate intrinsic coupling among the states, and (3) [bilinear] parameters that allow the inputs to modulate that coupling. Identification proceeds in a Bayesian framework given known, deterministic inputs and the observed responses of the system. We developed this approach for the analysis of effective connectivity using experimentally designed inputs and {fMRI} responses. In this context, the coupling parameters correspond to effective connectivity and the bilinear parameters reflect the changes in connectivity induced by inputs. The ensuing framework allows one to characterise {fMRI} experiments, conceptually, as an experimental manipulation of integration among brain regions (by contextual or trial-free inputs, like time or attentional set) that is revealed using evoked responses (to perturbations or trial-bound inputs, like stimuli). As with previous analyses of effective connectivity, the focus is on experimentally induced changes in coupling (cf., psychophysiologic interactions). However, unlike previous approaches in neuroimaging, the causal model ascribes responses to designed deterministic inputs, as opposed to treating inputs as unknown and stochastic.},
	pages = {1273--1302},
	number = {4},
	journaltitle = {{NeuroImage}},
	shortjournal = {{NeuroImage}},
	author = {Friston, K. J. and Harrison, L. and Penny, W.},
	urldate = {2020-05-01},
	date = {2003-08-01},
	langid = {english},
	keywords = {Bilinear model, Effective connectivity, {fMRI}, Functional neuroimaging, Hemodynamic response function, Nonlinear system identification},
}
@article{imperfect_datasets,
	title = {Embracing Imperfect Datasets: A Review of Deep Learning Solutions for Medical Image Segmentation},
	issn = {1361-8415},
	url = {http://www.sciencedirect.com/science/article/pii/S136184152030058X},
	doi = {10.1016/j.media.2020.101693},
	shorttitle = {Embracing Imperfect Datasets},
	abstract = {The medical imaging literature has witnessed remarkable progress in high-performing segmentation models based on convolutional neural networks. Despite the new performance highs, the recent advanced segmentation models still require large, representative, and high quality annotated datasets. However, rarely do we have a perfect training dataset, particularly in the field of medical imaging, where data and annotations are both expensive to acquire. Recently, a large body of research has studied the problem of medical image segmentation with imperfect datasets, tackling two major dataset limitations: scarce annotations where only limited annotated data is available for training, and weak annotations where the training data has only sparse annotations, noisy annotations, or image-level annotations. In this article, we provide a detailed review of the solutions above, summarizing both the technical novelties and empirical results. We further compare the benefits and requirements of the surveyed methodologies and provide our recommended solutions. We hope this survey article increases the community awareness of the techniques that are available to handle imperfect medical image segmentation datasets.},
	pages = {101693},
	journaltitle = {Medical Image Analysis},
	shortjournal = {Medical Image Analysis},
	author = {Tajbakhsh, Nima and Jeyaseelan, Laura and Li, Qian and Chiang, Jeffrey N. and Wu, Zhihao and Ding, Xiaowei},
	urldate = {2020-04-10},
	date = {2020-04-03},
	langid = {english},
	keywords = {and weak annotations, Imperfect dataset, Medical image segmentation, Noisy annotations, Scarce annotations, Sparse annotations, Unreliable annotations},
}


@online{imperferct_segmentaion_labels,
	title = {Imperfect Segmentation Labels: How Much Do They Matter?},
	url = {https://www.researchgate.net/publication/325733789_Imperfect_Segmentation_Labels_How_Much_Do_They_Matter},
	shorttitle = {Imperfect Segmentation Labels},
	abstract = {{ResearchGate} is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
	titleaddon = {{ResearchGate}},
	urldate = {2020-04-10},
	langid = {english},
	note = {Library Catalog: www.researchgate.net},
}

@software{mlebe_repsep,
	title = {Jimmy2027/mlebe\_RepSep},
	url = {https://github.com/Jimmy2027/mlebe_RepSep},
	abstract = {Contribute to Jimmy2027/mlebe\_RepSep development by creating an account on {GitHub}.},
	author = {Hendrik{\textbackslash}\_Klug},
	urldate = {2020-03-23},
	date = {2020-03-09},
	note = {original-date: 2020-01-20T16:51:45Z}
}
@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@software{mlebe,
	title = {Jimmy2027/{MLEBE}},
	rights = {{GPL}-3.0},
	url = {https://github.com/Jimmy2027/MLEBE},
	abstract = {Machine Learning Enabled Brain Extraction. Contribute to Jimmy2027/{MLEBE} development by creating an account on {GitHub}.},
	author = {Hendrik{\textbackslash}\_Klug},
	urldate = {2020-03-23},
	date = {2020-03-18},
	note = {original-date: 2019-10-13T09:57:20Z}
}
@misc{samri,
	author = {Horea-Ioan Ioanas and
		Markus Marks and
		Dominik Schmidt and
		Florian Aymanns and
		Markus Rudin},
	title = {{SAMRI} --- {S}mall {A}nimal {M}agnetic {R}esonance {I}maging},
	year = 2017,
	month = nov,
	doi = {10.5281/zenodo.1044033},
	url = {https://doi.org/10.5281/zenodo.1044033},
}
@article{sotiras_deformable_2013,
	title = {Deformable {Medical} {Image} {Registration}: {A} {Survey}},
	volume = {32},
	issn = {1558-254X},
	shorttitle = {Deformable {Medical} {Image} {Registration}},
	doi = {10.1109/TMI.2013.2265603},
	abstract = {Deformable image registration is a fundamental task in medical image processing. Among its most important applications, one may cite: 1) multi-modality fusion, where information acquired by different imaging devices or protocols is fused to facilitate diagnosis and treatment planning; 2) longitudinal studies, where temporal structural or anatomical changes are investigated; and 3) population modeling and statistical atlases used to study normal anatomical variability. In this paper, we attempt to give an overview of deformable registration methods, putting emphasis on the most recent advances in the domain. Additional emphasis has been given to techniques applied to medical images. In order to study image registration methods in depth, their main components are identified and studied independently. The most recent techniques are presented in a systematic fashion. The contribution of this paper is to provide an extensive account of registration techniques in a systematic manner.},
	number = {7},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Sotiras, Aristeidis and Davatzikos, Christos and Paragios, Nikos},
	month = jul,
	year = {2013},
	keywords = {Algorithms, Bibliographical review, Biomedical imaging, Computational modeling, Deformable models, Diagnostic Imaging, Humans, Image Processing, Computer-Assisted, Image registration, Linear programming, Mathematical model, Topology, deformable medical image registration, deformable registration, diagnosis, image fusion, image registration, imaging devices, information acquisition, medical image analysis, medical image processing, multimodality fusion, normal anatomical variability, patient treatment, population modeling, protocols, statistical analysis, statistical atlases, temporal anatomical changes, temporal structural changes, treatment planning},
	pages = {1153--1190}
}
@article{eklund2016cluster,
	title = {Cluster failure: why f{MRI} inferences for spatial extent have inflated false-positive rates},
	author = {Eklund, Anders and Nichols, Thomas E and Knutsson, Hans},
	journal = {Proceedings of the National Academy of Sciences},
	pages = {201602413},
	year = 2016,
	month = jun,
	publisher = {National Acad Sciences},
	doi ={10.1073/pnas.1602413113},
	url ={https://doi.org/10.1073/pnas.1602413113},
}
@Article{nipype,
	Title = {Nipype: A Flexible, Lightweight and Extensible Neuroimaging Data Processing Framework in {P}ython},
	Author = {
		Gorgolewski, Krzysztof and
		Burns, Christopher D. and
		Madison, Cindeeand
		Clark, Dav and
		Halchenko, Yaroslav O. and
		Waskom, Michael L. and
		Ghosh, Satrajit S.
		},
	Journal = {Front. Neuroinform.},
	Year = {2011},
	Volume = {5},

	ISSN = {1662-5196},
	Owner = {chymera},
	Publisher = {Frontiers Media SA},
	Timestamp = {2015.04.13},
	url = {http://dx.doi.org/10.3389/fninf.2011.00013},
	doi = {10.3389/fninf.2011.00013},
}
@article{cox1996afni,
	title = {{AFNI}: software for analysis and visualization of functional magnetic resonance neuroimages},
	author = {Cox, Robert W},
	journal = {Computers and Biomedical research},
	volume = {29},
	number = {3},
	pages = {162--173},
	year = 1996,
	month = jun,
	url = {https://www.sciencedirect.com/science/article/pii/S0010480996900142},
	doi = {10.1006/cbmr.1996.0014},
	publisher = {Elsevier},
}
@article{cox2017fmri,
	title = {{FMRI} clustering in {AFNI}: false-positive rates redux},
	author = {Cox, Robert W and Chen, Gang and Glen, Daniel R and Reynolds, Richard C and Taylor, Paul A},
	journal = {Brain connectivity},
	volume = {7},
	number = {3},
	pages = {152--171},
	year = 2017,
	month = apr,
	doi = {10.1089/brain.2016.0475},
	url = {https://doi.org/10.1089/brain.2016.0475},
	publisher = {Mary Ann Liebert, Inc. 140 Huguenot Street, 3rd Floor New Rochelle, NY 10801 USA},
}
@article{li_non-rigid_2017,
	title = {Non-rigid image registration using fully convolutional networks with deep self-supervision},
	url = {http://arxiv.org/abs/1709.00799},
	abstract = {We propose a novel non-rigid image registration algorithm that is built upon fully convolutional networks (FCNs) to optimize and learn spatial transformations between pairs of images to be registered. Different from most existing deep learning based image registration methods that learn spatial transformations from training data with known corresponding spatial transformations, our method directly estimates spatial transformations between pairs of images by maximizing an image-wise similarity metric between fixed and deformed moving images, similar to conventional image registration algorithms. At the same time, our method also learns FCNs for encoding the spatial transformations at the same spatial resolution of images to be registered, rather than learning coarse-grained spatial transformation information. The image registration is implemented in a multi-resolution image registration framework to jointly optimize and learn spatial transformations and FCNs at different resolutions with deep self-supervision through typical feedforward and backpropagation computation. Since our method simultaneously optimizes and learns spatial transformations for the image registration, our method can be directly used to register a pair of images, and the registration of a set of images is also a training procedure for FCNs so that the trained FCNs can be directly adopted to register new images by feedforward computation of the learned FCNs without any optimization. The proposed method has been evaluated for registering 3D structural brain magnetic resonance (MR) images and obtained better performance than state-of-the-art image registration algorithms.},
	urldate = {2020-01-20},
	journal = {arXiv:1709.00799 [cs]},
	author = {Li, Hongming and Fan, Yong},
	month = sep,
	year = {2017},
	note = {arXiv: 1709.00799},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{perez_effectiveness_2017,
	title = {The {Effectiveness} of {Data} {Augmentation} in {Image} {Classification} using {Deep} {Learning}},
	url = {http://arxiv.org/abs/1712.04621},
	abstract = {In this paper, we explore and compare multiple solutions to the problem of data augmentation in image classification. Previous work has demonstrated the effectiveness of data augmentation through simple techniques, such as cropping, rotating, and flipping input images. We artificially constrain our access to data to a small subset of the ImageNet dataset, and compare each data augmentation technique in turn. One of the more successful data augmentations strategies is the traditional transformations mentioned above. We also experiment with GANs to generate images of different styles. Finally, we propose a method to allow a neural net to learn augmentations that best improve the classifier, which we call neural augmentation. We discuss the successes and shortcomings of this method on various datasets.},
	urldate = {2020-01-19},
	journal = {arXiv:1712.04621 [cs]},
	author = {Perez, Luis and Wang, Jason},
	month = dec,
	year = {2017},
	note = {arXiv: 1712.04621},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{maintz_overview_nodate,
	title = {An {Overview} of {Medical} {Image} {Registration} {Methods}},
	abstract = {The purpose of this paper is to present an overview of existing medical image registration methods. These methods will be classiﬁed according to a model based on nine salient criteria, the main dichotomy of which is extrinsic versus intrinsic methods. The statistics of the classiﬁcation show deﬁnite trends in the evolving registration techniques, which will be discussed. At this moment, the bulk of interesting intrinsic methods is either based on segmented points or surfaces, or on techniques endeavoring to use the full information content of the images involved.},
	language = {en},
	author = {Maintz, J B Antoine and Viergever, Max A},
	pages = {22}
}

@article{geng_survey_2018,
	title = {Survey of recent progress in semantic image segmentation with {CNNs}},
	volume = {61},
	issn = {1674-733X, 1869-1919},
	url = {http://link.springer.com/10.1007/s11432-017-9189-6},
	doi = {10.1007/s11432-017-9189-6},
	abstract = {In recent years, convolutional neural networks (CNNs) are leading the way in many computer vision tasks, such as image classiﬁcation, object detection, and face recognition. In order to produce more reﬁned semantic image segmentation, we survey the powerful CNNs and novel elaborate layers, structures and strategies, especially including those that have achieved the state-of-the-art results on the Pascal VOC 2012 semantic segmentation challenge. Moreover, we discuss their diﬀerent working stages and various mechanisms to utilize the structural and contextual information in the image and feature spaces. Finally, combining some popular underlying referential methods in homologous problems, we propose several possible directions and approaches to incorporate existing eﬀective methods as components to enhance CNNs for the segmentation of speciﬁc semantic objects.},
	language = {en},
	number = {5},
	urldate = {2020-01-17},
	journal = {Science China Information Sciences},
	author = {Geng, Qichuan and Zhou, Zhong and Cao, Xiaochun},
	month = may,
	year = {2018},
	pages = {051101}
}

@article{madry_towards_2019,
	title = {Towards {Deep} {Learning} {Models} {Resistant} to {Adversarial} {Attacks}},
	url = {http://arxiv.org/abs/1706.06083},
	abstract = {Recent work has demonstrated that deep neural networks are vulnerable to adversarial examples---inputs that are almost indistinguishable from natural data and yet classified incorrectly by the network. In fact, some of the latest findings suggest that the existence of adversarial attacks may be an inherent weakness of deep learning models. To address this problem, we study the adversarial robustness of neural networks through the lens of robust optimization. This approach provides us with a broad and unifying view on much of the prior work on this topic. Its principled nature also enables us to identify methods for both training and attacking neural networks that are reliable and, in a certain sense, universal. In particular, they specify a concrete security guarantee that would protect against any adversary. These methods let us train networks with significantly improved resistance to a wide range of adversarial attacks. They also suggest the notion of security against a first-order adversary as a natural and broad security guarantee. We believe that robustness against such well-defined classes of adversaries is an important stepping stone towards fully resistant deep learning models. Code and pre-trained models are available at https://github.com/MadryLab/mnist\_challenge and https://github.com/MadryLab/cifar10\_challenge.},
	urldate = {2020-01-10},
	journal = {arXiv:1706.06083 [cs, stat]},
	author = {Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
	month = sep,
	year = {2019},
	note = {arXiv: 1706.06083},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning}
}

@article{ioanas_effects_nodate,
	title = {Effects of {Acute} and {Chronic} {Reuptake} {Inhibition} on {Optogenetically} {Induced} {Serotonergic} {Activity}},
	abstract = {The serotonergic system is widely implicated in aﬀect regulation, and a common target for psychopharmacological interventions. Selective Serotonin Reuptake Inhibitors (SSRIs) are the foremost drug class for treating depression, and also ﬁnd use in treating anxiety, phobia and other aﬀective disorders. However, the understanding of SSRI eﬀect mechanics is limited, thus hindering advancements in serotonergic manipulation. Moreover, high-power assays for longitudinal whole-brain interrogation of the serotonergic system are unavailable, yet such techniques are essential for evaluating diﬀerential eﬀects across projection areas. We present a longitudinal opto-fMRI assay suitable for exploring longitudinal drug treatment eﬀects on the mouse serotonergic system — within-subject and with sub-millimetre spatial resolution. This allowed segmentation of the brain into three longitudinal trajectory clusters, following two distinct patterns, which support the autoinhibition downregulation theory of SSRI eﬀects. We show that given the sensitivity of the assay, SSRI treatment produces no persistent eﬀects after treatment cessation in healthy subjects.},
	language = {en},
	author = {Ioanas, Horea-Ioan and Saab, Bechara John and Rudin, Markus},
	pages = {20}
}

@article{ioanas_whole-brain_nodate,
	title = {A {Whole}-{Brain} {Map} and {Assay} {Parameter} {Analysis} of {Mouse} {VTA} {Dopaminergic} {Activation}},
	abstract = {Ascending dopaminergic projections from neurons located in the Ventral Tegmental Area (VTA) are key to the etiology, dysfunction, and control of motivation, learning, and addiction. Due to evolutionary conservation of this nucleus and the extensive use of mice as disease models, establishing an assay for VTA dopaminergic signalling in the mouse brain is crucial for the translational investigation of neuronal function phenotypes of diseases and interventions. In this article we use optogenetic stimulation for targeted VTA dopaminergic neuron control, in combination with functional Magnetic Resonance Imaging (fMRI), a method widely used in human deep brain imaging. We present the ﬁrst whole-brain opto-fMRI map of VTA dopaminergic activation in the mouse, and show that dopaminergic system function is consistent with but diverges in a few key aspects from its structure. While the activation map predominantly includes and excludes target areas according to their relative projection densities (e.g. strong activation of the nucleus accumbens and low activation of the hippocampus), it also includes areas for which a structural connection is not well established (such as the dorsal striatum). We further detail assay variability with regard to multiple experimental parameters, including stimulation protocol and implant position, and provide detailed evidence-based recommendations for assay reuse.},
	language = {en},
	author = {Ioanas, Horea-Ioan and Saab, Bechara John and Rudin, Markus},
	pages = {19}
}

@misc{noauthor_multi-dimensional_nodate-1,
	title = {Multi-dimensional image processing (scipy.ndimage) — {SciPy} v1.4.1 {Reference} {Guide}},
	url = {https://docs.scipy.org/doc/scipy/reference/ndimage.html#morphology},
	urldate = {2020-01-07}
}

@misc{noauthor_neuroimaging_nodate,
	title = {Neuroimaging in {Python} — {NiBabel} 2.5.0 documentation},
	url = {https://nipy.org/nibabel/},
	urldate = {2020-01-07}
}

@article{milletari_v-net:_2016,
	title = {V-{Net}: {Fully} {Convolutional} {Neural} {Networks} for {Volumetric} {Medical} {Image} {Segmentation}},
	shorttitle = {V-{Net}},
	url = {http://arxiv.org/abs/1606.04797},
	abstract = {Convolutional Neural Networks (CNNs) have been recently employed to solve problems from both the computer vision and medical image analysis fields. Despite their popularity, most approaches are only able to process 2D images while most medical data used in clinical practice consists of 3D volumes. In this work we propose an approach to 3D image segmentation based on a volumetric, fully convolutional, neural network. Our CNN is trained end-to-end on MRI volumes depicting prostate, and learns to predict segmentation for the whole volume at once. We introduce a novel objective function, that we optimise during training, based on Dice coefficient. In this way we can deal with situations where there is a strong imbalance between the number of foreground and background voxels. To cope with the limited number of annotated volumes available for training, we augment the data applying random non-linear transformations and histogram matching. We show in our experimental evaluation that our approach achieves good performances on challenging test data while requiring only a fraction of the processing time needed by other previous methods.},
	urldate = {2020-01-05},
	journal = {arXiv:1606.04797 [cs]},
	author = {Milletari, Fausto and Navab, Nassir and Ahmadi, Seyed-Ahmad},
	month = jun,
	year = {2016},
	note = {arXiv: 1606.04797},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@misc{noauthor_ibt-fmi/samri_2019,
	title = {{IBT}-{FMI}/{SAMRI}},
	copyright = {GPL-3.0},
	url = {https://github.com/IBT-FMI/SAMRI},
	abstract = {Small Animal Magnetic Resonance Imaging via Python.},
	urldate = {2020-01-05},
	publisher = {Functional and Molecular Imaging @IBT(ETH/UZH)},
	month = dec,
	year = {2019},
	note = {original-date: 2015-04-27T00:26:08Z},
	keywords = {bids, biomedical, dwi, fmri, fsl, functional-connectivity, neuroimaging, registration, rodent, small-animals}
}

@misc{noauthor_callbacks_nodate,
	title = {Callbacks - {Keras} {Documentation}},
	url = {https://keras.io/callbacks/},
	urldate = {2020-01-05}
}

@article{srivastava2014dropout,
  title={Dropout: a simple way to prevent neural networks from overfitting},
  author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={The journal of machine learning research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014},
  publisher={JMLR. org}
}

@misc{zhixuhao_zhixuhao/unet_2020,
	title = {zhixuhao/unet},
	copyright = {MIT},
	url = {https://github.com/zhixuhao/unet},
	abstract = {unet for image segmentation. Contribute to zhixuhao/unet development by creating an account on GitHub.},
	urldate = {2020-01-05},
	author = {zhixuhao},
	month = jan,
	year = {2020},
	note = {original-date: 2017-04-06T01:58:15Z},
	keywords = {keras, segmentation, unet}
}

@article{ronneberger_u-net:_2015,
	title = {U-{Net}: {Convolutional} {Networks} for {Biomedical} {Image} {Segmentation}},
	shorttitle = {U-{Net}},
	url = {http://arxiv.org/abs/1505.04597},
	abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
	urldate = {2020-01-05},
	journal = {arXiv:1505.04597 [cs]},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	month = may,
	year = {2015},
	note = {arXiv: 1505.04597
version: 1},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@techreport{ioanas_optimized_2019,
	type = {preprint},
	title = {An {Optimized} {Registration} {Workflow} and {Standard} {Geometric} {Space} for {Small} {Animal} {Brain} {Imaging}},
	url = {http://biorxiv.org/lookup/doi/10.1101/619650},
	abstract = {The reliability of scientiﬁc results critically depends on reproducible and transparent data processing. Cross-subject and cross-study comparability of imaging data in general, and magnetic resonance imaging (MRI) data in particular, is contingent on the quality of registration to a standard reference space. In small animal MRI this is not adequately provided by currently used processing workﬂows, which utilize highlevel scripts optimized for human data, and adapt animal data to ﬁt the scripts, rather than vice-versa. In this fully reproducible article we showcase a generic workﬂow optimized for the mouse brain, alongside a standard reference space suited to harmonize data between analysis and operation. We present four separate metrics for automated quality control (QC), and a visualization method to aid operator inspection. Benchmarking this workﬂow against common legacy practices reveals that it performs more consistently, better preserves variance across subjects while minimizing variance across sessions, and improves both volume and smoothness conservation RMSE approximately 3-fold. We propose this open source workﬂow and the QC metrics as a new standard for small animal MRI registration, ensuring workﬂow robustness, data comparability, and region assignment validity, important criteria for the comparability of scientiﬁc results across experiments and centers.},
	language = {en},
	urldate = {2020-01-05},
	institution = {Neuroscience},
	author = {Ioanas, Horea-Ioan and Marks, Markus and Yanik, Mehmet Fatih and Rudin, Markus},
	month = apr,
	year = {2019},
	doi = {10.1101/619650}
}


@article{vartiainen_halo_2014,
	title = {Halo suppression in full-field x-ray {Zernike} phase contrast microscopy},
	volume = {39},
	issn = {0146-9592, 1539-4794},
	url = {https://www.osapublishing.org/abstract.cfm?URI=ol-39-6-1601},
	doi = {10.1364/OL.39.001601},
	language = {en},
	number = {6},
	urldate = {2019-11-21},
	journal = {Optics Letters},
	author = {Vartiainen, Ismo and Mokso, Rajmund and Stampanoni, Marco and David, Christian},
	month = mar,
	year = {2014},
	pages = {1601}
}

@article{pfeiffer_x-ray_2018,
	title = {X-ray ptychography},
	volume = {12},
	issn = {1749-4885, 1749-4893},
	url = {http://www.nature.com/articles/s41566-017-0072-5},
	doi = {10.1038/s41566-017-0072-5},
	language = {en},
	number = {1},
	urldate = {2019-11-20},
	journal = {Nature Photonics},
	author = {Pfeiffer, Franz},
	month = jan,
	year = {2018},
	pages = {9--17}
}

@article{pfeiffer_x-ray_2018-1,
	title = {X-ray ptychography},
	volume = {12},
	copyright = {2017 © Macmillan Publishers Limited, part of Springer Nature 2017},
	issn = {1749-4893},
	url = {https://www.nature.com/articles/s41566-017-0072-5},
	doi = {10.1038/s41566-017-0072-5},
	abstract = {This Review covers key advancements in X-ray ptychographic microscopy and tomography over the past ten years. Potential applications in the life and materials sciences, the latest concepts and future developments are also discussed.},
	language = {en},
	number = {1},
	urldate = {2019-11-19},
	journal = {Nature Photonics},
	author = {Pfeiffer, Franz},
	month = jan,
	year = {2018},
	pages = {9--17}
}

@article{athalye_obfuscated_2018,
	title = {Obfuscated {Gradients} {Give} a {False} {Sense} of {Security}: {Circumventing} {Defenses} to {Adversarial} {Examples}},
	shorttitle = {Obfuscated {Gradients} {Give} a {False} {Sense} of {Security}},
	url = {http://arxiv.org/abs/1802.00420},
	abstract = {We identify obfuscated gradients, a kind of gradient masking, as a phenomenon that leads to a false sense of security in defenses against adversarial examples. While defenses that cause obfuscated gradients appear to defeat iterative optimization-based attacks, we find defenses relying on this effect can be circumvented. We describe characteristic behaviors of defenses exhibiting the effect, and for each of the three types of obfuscated gradients we discover, we develop attack techniques to overcome it. In a case study, examining non-certified white-box-secure defenses at ICLR 2018, we find obfuscated gradients are a common occurrence, with 7 of 9 defenses relying on obfuscated gradients. Our new attacks successfully circumvent 6 completely, and 1 partially, in the original threat model each paper considers.},
	urldate = {2019-11-15},
	journal = {arXiv:1802.00420 [cs]},
	author = {Athalye, Anish and Carlini, Nicholas and Wagner, David},
	month = jul,
	year = {2018},
	note = {arXiv: 1802.00420},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security, Computer Science - Machine Learning}
}

@article{hannun_deep_2014,
	title = {Deep {Speech}: {Scaling} up end-to-end speech recognition},
	shorttitle = {Deep {Speech}},
	url = {http://arxiv.org/abs/1412.5567},
	abstract = {We present a state-of-the-art speech recognition system developed using end-to-end deep learning. Our architecture is significantly simpler than traditional speech systems, which rely on laboriously engineered processing pipelines; these traditional systems also tend to perform poorly when used in noisy environments. In contrast, our system does not need hand-designed components to model background noise, reverberation, or speaker variation, but instead directly learns a function that is robust to such effects. We do not need a phoneme dictionary, nor even the concept of a "phoneme." Key to our approach is a well-optimized RNN training system that uses multiple GPUs, as well as a set of novel data synthesis techniques that allow us to efficiently obtain a large amount of varied data for training. Our system, called Deep Speech, outperforms previously published results on the widely studied Switchboard Hub5'00, achieving 16.0\% error on the full test set. Deep Speech also handles challenging noisy environments better than widely used, state-of-the-art commercial speech systems.},
	urldate = {2019-11-09},
	journal = {arXiv:1412.5567 [cs]},
	author = {Hannun, Awni and Case, Carl and Casper, Jared and Catanzaro, Bryan and Diamos, Greg and Elsen, Erich and Prenger, Ryan and Satheesh, Sanjeev and Sengupta, Shubho and Coates, Adam and Ng, Andrew Y.},
	month = dec,
	year = {2014},
	note = {arXiv: 1412.5567},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing}
}

@article{tsipras_robustness_2019,
	title = {Robustness {May} {Be} at {Odds} with {Accuracy}},
	url = {http://arxiv.org/abs/1805.12152},
	abstract = {We show that there may exist an inherent tension between the goal of adversarial robustness and that of standard generalization. Speciﬁcally, training robust models may not only be more resource-consuming, but also lead to a reduction of standard accuracy. We demonstrate that this trade-off between the standard accuracy of a model and its robustness to adversarial perturbations provably exists in a fairly simple and natural setting. These ﬁndings also corroborate a similar phenomenon observed empirically in more complex settings. Further, we argue that this phenomenon is a consequence of robust classiﬁers learning fundamentally different feature representations than standard classiﬁers. These differences, in particular, seem to result in unexpected beneﬁts: the representations learned by robust models tend to align better with salient data characteristics and human perception.},
	language = {en},
	urldate = {2019-11-09},
	journal = {arXiv:1805.12152 [cs, stat]},
	author = {Tsipras, Dimitris and Santurkar, Shibani and Engstrom, Logan and Turner, Alexander and Madry, Aleksander},
	month = sep,
	year = {2019},
	note = {arXiv: 1805.12152},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning}
}

@article{madry_towards_2019-1,
	title = {Towards {Deep} {Learning} {Models} {Resistant} to {Adversarial} {Attacks}},
	url = {http://arxiv.org/abs/1706.06083},
	abstract = {Recent work has demonstrated that deep neural networks are vulnerable to adversarial examples---inputs that are almost indistinguishable from natural data and yet classified incorrectly by the network. In fact, some of the latest findings suggest that the existence of adversarial attacks may be an inherent weakness of deep learning models. To address this problem, we study the adversarial robustness of neural networks through the lens of robust optimization. This approach provides us with a broad and unifying view on much of the prior work on this topic. Its principled nature also enables us to identify methods for both training and attacking neural networks that are reliable and, in a certain sense, universal. In particular, they specify a concrete security guarantee that would protect against any adversary. These methods let us train networks with significantly improved resistance to a wide range of adversarial attacks. They also suggest the notion of security against a first-order adversary as a natural and broad security guarantee. We believe that robustness against such well-defined classes of adversaries is an important stepping stone towards fully resistant deep learning models. Code and pre-trained models are available at https://github.com/MadryLab/mnist\_challenge and https://github.com/MadryLab/cifar10\_challenge.},
	language = {en},
	urldate = {2019-11-09},
	journal = {arXiv:1706.06083 [cs, stat]},
	author = {Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
	month = sep,
	year = {2019},
	note = {arXiv: 1706.06083},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning}
}

@article{carlini_audio_2018,
	title = {Audio {Adversarial} {Examples}: {Targeted} {Attacks} on {Speech}-to-{Text}},
	shorttitle = {Audio {Adversarial} {Examples}},
	url = {http://arxiv.org/abs/1801.01944},
	abstract = {We construct targeted audio adversarial examples on automatic speech recognition. Given any audio waveform, we can produce another that is over 99.9\% similar, but transcribes as any phrase we choose (recognizing up to 50 characters per second of audio). We apply our white-box iterative optimization-based attack to Mozilla’s implementation DeepSpeech end-to-end, and show it has a 100\% success rate. The feasibility of this attack introduce a new domain to study adversarial examples.},
	language = {en},
	urldate = {2019-11-09},
	journal = {arXiv:1801.01944 [cs]},
	author = {Carlini, Nicholas and Wagner, David},
	month = mar,
	year = {2018},
	note = {arXiv: 1801.01944},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security, Computer Science - Machine Learning}
}

@article{modregger_grating-based_nodate,
	title = {Grating-{Based} {X}-{Ray} {Phase}- {Contrast} {Imaging}},
	language = {en},
	author = {Modregger, Peter and Pinzer, Bernd and Wang, Zhentian and Stampanoni, Marco},
	pages = {14}
}

@article{howells_introduction:_2009,
	title = {Introduction: {Special} issue on radiation damage},
	volume = {170},
	issn = {03682048},
	shorttitle = {Introduction},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0368204809000176},
	doi = {10.1016/j.elspec.2009.01.004},
	language = {en},
	number = {1-3},
	urldate = {2019-11-09},
	journal = {Journal of Electron Spectroscopy and Related Phenomena},
	author = {Howells, Malcolm R. and Hitchcock, Adam P. and Jacobsen, Chris J.},
	month = mar,
	year = {2009},
	pages = {1--3}
}

@article{fouras_past_2009,
	title = {The past, present, and future of x-ray technology for \textit{in vivo} imaging of function and form},
	volume = {105},
	issn = {0021-8979, 1089-7550},
	url = {http://aip.scitation.org/doi/10.1063/1.3115643},
	doi = {10.1063/1.3115643},
	language = {en},
	number = {10},
	urldate = {2019-11-09},
	journal = {Journal of Applied Physics},
	author = {Fouras, A. and Kitchen, M. J. and Dubsky, S. and Lewis, R. A. and Hooper, S. B. and Hourigan, K.},
	month = may,
	year = {2009},
	pages = {102009}
}

@article{paganin_simultaneous_2002,
	title = {Simultaneous phase and amplitude extraction from a single defocused image of a homogeneous object},
	volume = {206},
	issn = {0022-2720, 1365-2818},
	url = {http://doi.wiley.com/10.1046/j.1365-2818.2002.01010.x},
	doi = {10.1046/j.1365-2818.2002.01010.x},
	abstract = {We demonstrate simultaneous phase and amplitude extraction from a single defocused image of a homogeneous object. Subject to the assumptions explicitly stated in the derivation, the algorithm solves the twin-image problem of in-line holography and is capable of analysing data obtained using X-ray microscopy, electron microscopy, neutron microscopy or visible-light microscopy, especially as they relate to defocus and point projection methods. Our simple, robust, non-iterative and computationally efﬁcient method is applied to data obtained using an X-ray phase contrast ultramicroscope.},
	language = {en},
	number = {1},
	urldate = {2019-11-09},
	journal = {Journal of Microscopy},
	author = {Paganin, D. and Mayo, S. C. and Gureyev, T. E. and Miller, P. R. and Wilkins, S. W.},
	month = apr,
	year = {2002},
	pages = {33--40}
}

@article{meyer-ilse_high_2001,
	title = {High resolution protein localization using soft {X}-ray microscopy},
	volume = {201},
	issn = {0022-2720, 1365-2818},
	url = {http://doi.wiley.com/10.1046/j.1365-2818.2001.00845.x},
	doi = {10.1046/j.1365-2818.2001.00845.x},
	abstract = {Soft X-ray microscopes can be used to examine whole, hydrated cells up to 10 mm thick and produce images approaching 30 nm resolution. Since cells are imaged in the X-ray transmissive `water window', where organic material absorbs approximately an order of magnitude more strongly than water, chemical contrast enhancement agents are not required to view the distribution of cellular structures. Although living specimens cannot be examined, cells can be rapidly frozen at a precise moment in time and examined in a cryostage, revealing information that most closely approximates that in live cells. In this study, we used a transmission X-ray microscope at photon energies just below the oxygen edge (l  2.4 nm) to examine rapidly frozen mouse 3T3 cells and obtained excellent cellular morphology at better than 50 nm lateral resolution. These specimens are extremely stable, enabling multiple exposures with virtually no detectable damage to cell structures. We also show that silver-enhanced, immunogold labelling can be used to localize both cytoplasmic and nuclear proteins in whole, hydrated mammary epithelial cells at better than 50 nm resolution. The future use of X-ray tomography, along with improved zone plate lenses, will enable collection of better resolution (approaching 30 nm), three-dimensional information on the distribution of proteins in cells.},
	language = {en},
	number = {3},
	urldate = {2019-11-09},
	journal = {Journal of Microscopy},
	author = {Meyer-Ilse, W. and Hamamoto, D. and Nair, A. and Lelievre, S. A. and Denbeaux, G. and Johnson, L. and Pearson, A. L. and Yager, D. and Legros, M. A. and Larabell, C. A.},
	month = mar,
	year = {2001},
	pages = {395--403}
}

@article{busch_x-ray_nodate,
	title = {X-{RAY} {COMPUTED} {MICROTOMOGRAPHY} ({pCT}) {USING} {SYNCHROTRON} {RADIATION} ({SR})},
	language = {en},
	author = {Busch, Frank},
	pages = {37}
}

@article{xu_deepatlas:_2019,
	title = {{DeepAtlas}: {Joint} {Semi}-{Supervised} {Learning} of {Image} {Registration} and {Segmentation}},
	shorttitle = {{DeepAtlas}},
	url = {http://arxiv.org/abs/1904.08465},
	abstract = {Deep convolutional neural networks (CNNs) are state-of-the-art for semantic image segmentation, but typically require many labeled training samples. Obtaining 3D segmentations of medical images for supervised training is difficult and labor intensive. Motivated by classical approaches for joint segmentation and registration we therefore propose a deep learning framework that jointly learns networks for image registration and image segmentation. In contrast to previous work on deep unsupervised image registration, which showed the benefit of weak supervision via image segmentations, our approach can use existing segmentations when available and computes them via the segmentation network otherwise, thereby providing the same registration benefit. Conversely, segmentation network training benefits from the registration, which essentially provides a realistic form of data augmentation. Experiments on knee and brain 3D magnetic resonance (MR) images show that our approach achieves large simultaneous improvements of segmentation and registration accuracy (over independently trained networks) and allows training high-quality models with very limited training data. Specifically, in a one-shot-scenario (with only one manually labeled image) our approach increases Dice scores (\%) over an unsupervised registration network by 2.7 and 1.8 on the knee and brain images respectively.},
	urldate = {2019-11-09},
	journal = {arXiv:1904.08465 [cs]},
	author = {Xu, Zhenlin and Niethammer, Marc},
	month = jul,
	year = {2019},
	note = {arXiv: 1904.08465},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{zhou_normalization_2019,
	title = {Normalization in {Training} {U}-{Net} for 2D {Biomedical} {Semantic} {Segmentation}},
	url = {http://arxiv.org/abs/1809.03783},
	abstract = {2D biomedical semantic segmentation is important for robotic vision in surgery. Segmentation methods based on Deep Convolutional Neural Network (DCNN) can out-perform conventional methods in terms of both accuracy and levels of automation. One common issue in training a DCNN for biomedical semantic segmentation is the internal covariate shift where the training of convolutional kernels is encumbered by the distribution change of input features, hence both the training speed and performance are decreased. Batch Normalization (BN) is the first proposed method for addressing internal covariate shift and is widely used. Instance Normalization (IN) and Layer Normalization (LN) have also been proposed. Group Normalization (GN) is proposed more recently and has not yet been applied to 2D biomedical semantic segmentation, however, no specific validations on GN were given. Most DCNNs for biomedical semantic segmentation adopt BN as the normalization method by default, without reviewing its performance. In this paper, four normalization methods - BN, IN, LN and GN are compared in details, specifically for 2D biomedical semantic segmentation. U-Net is adopted as the basic DCNN structure. Three datasets regarding the Right Ventricle (RV), aorta, and Left Ventricle (LV) are used for the validation. The results show that detailed subdivision of the feature map, i.e. GN with a large group number or IN, achieves higher accuracy. This accuracy improvement mainly comes from better model generalization. Codes are uploaded and maintained at Xiao-Yun Zhou's Github.},
	urldate = {2019-11-09},
	journal = {arXiv:1809.03783 [cs]},
	author = {Zhou, Xiao-Yun and Yang, Guang-Zhong},
	month = jan,
	year = {2019},
	note = {arXiv: 1809.03783},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{wakonig_x-ray_2019,
	title = {X-ray {Fourier} ptychography},
	volume = {5},
	issn = {2375-2548},
	url = {http://advances.sciencemag.org/lookup/doi/10.1126/sciadv.aav0282},
	doi = {10.1126/sciadv.aav0282},
	abstract = {To a large extent, the performance of imaging systems is determined by their objectives, which affect properties as varied as collection efficiency, resolving power, and image distortions. Such limitations can be addressed by so-called aperture synthesis, a technique used, for instance, in radar, astronomy, and, increasingly, microscopy. Here, we apply such techniques to x-ray imaging and demonstrate how Fourier ptychography can be used at transmission x-ray microscopes to increase resolution, provide quantitative absorption and phase contrast, and allow for corrections of lens aberrations. We anticipate that such methods will find common and frequent applications, alleviating a number of limitations imposed by x-ray optical elements, offering an alternative approach to phase contrast imaging, and providing novel opportunities to mitigate radiation damage.},
	language = {en},
	number = {2},
	urldate = {2019-11-09},
	journal = {Science Advances},
	author = {Wakonig, Klaus and Diaz, Ana and Bonnin, Anne and Stampanoni, Marco and Bergamaschi, Anna and Ihli, Johannes and Guizar-Sicairos, Manuel and Menzel, Andreas},
	month = feb,
	year = {2019},
	pages = {eaav0282}
}

@article{patera_non-rigid_2018,
	title = {A non-rigid registration method for the analysis of local deformations in the wood cell wall},
	volume = {4},
	issn = {2198-0926},
	url = {https://ascimaging.springeropen.com/articles/10.1186/s40679-018-0050-0},
	doi = {10.1186/s40679-018-0050-0},
	abstract = {This paper concerns the problem of wood cellular structure image registration. Given the large variability of wood geometry and the important changes in the cellular organization due to moisture sorption, an affine-based image registration technique is not exhaustive to describe the overall hygro-mechanical behaviour of wood at micrometre scales. Additionally, free tools currently available for non-rigid image registration are not suitable for quantifying the structural deformations of complex hierarchical materials such as wood, leading to errors due to misalignment. In this paper, we adapt an existing non-rigid registration model based on B-spline functions to our case study. The so-modified algorithm combines the concept of feature recognition within specific regions locally distributed in the material with an optimization problem. Results show that the method is able to quantify local deformations induced by moisture changes in tomographic images of wood cell wall with high accuracy. The local deformations provide new important insights in characterizing the swelling behaviour of wood at the cell wall level.},
	language = {en},
	number = {1},
	urldate = {2019-11-09},
	journal = {Advanced Structural and Chemical Imaging},
	author = {Patera, Alessandra and Carl, Stephan and Stampanoni, Marco and Derome, Dominique and Carmeliet, Jan},
	month = dec,
	year = {2018},
	pages = {1}
}

@article{ants,
  title={Advanced normalization tools (ANTS)},
  author={Avants, Brian B and Tustison, Nick and Song, Gang},
  journal={Insight j},
  volume={2},
  number={365},
  pages={1--35},
  year={2009}
}

@article{noauthor_opencv-python_nodate,
    author = {Bradski, G.},
    citeulike-article-id = {2236121},
    journal = {Dr. Dobb's Journal of Software Tools},
    keywords = {bibtex-import},
    posted-at = {2008-01-15 19:21:54},
    priority = {4},
    title = {{The OpenCV Library}},
    year = {2000}
}

@article{fsl,
  title={Fsl},
  author={Jenkinson, Mark and Beckmann, Christian F and Behrens, Timothy EJ and Woolrich, Mark W and Smith, Stephen M},
  journal={Neuroimage},
  volume={62},
  number={2},
  pages={782--790},
  year={2012},
  publisher={Elsevier}
}

@conference{repsep,
	author = {Horea-Ioan Ioanas and Markus Rudin},
	title = {Reproducible Self-Publishing for {P}ython-Based Research},
	year = 2018,
	month = aug,
	publisher = {EuroSciPy},
	url = {https://figshare.com/articles/Reproducible_Self-Publishing_for_Python-Based_Research/7247339},
	doi = {10.6084/m9.figshare.7247339.v1},
}

@MANUAL{numpy,
	author = {Oliphant, Travis E.},
	title = {Guide to NumPy},
	year = 2006,
	month = mar,
	address = {Provo, UT},
	institution = {Brigham Young University},
	url = {https://www.numpy.org/devdocs/contents.html},
	keywords = {numpy},
}

@article{Molloy2014,
	doi = {10.1016/j.neuroimage.2013.09.001},
	url = {https://doi.org/10.1016/j.neuroimage.2013.09.001},
	year = 2014,
	month = feb,
	publisher = {Elsevier {BV}},
	volume = {86},
	pages = {221--230},
	author = {Erin K. Molloy and Mary E. Meyerand and Rasmus M. Birn},
	title = {The influence of spatial resolution and smoothing on the detectability of resting-state and task {fMRI}},
	journal = {{NeuroImage}}
}

@misc{irsabi_bidsdata,
	author = {Ioanas, Horea-Ioan and
	         Rudin, Markus},
	title = {{BIDS Data for "An Optimized Registration Workflow and Standard Geometric Space for Small Animal Brain Imaging"}},
	month = apr,
	year = 2019,
	doi = {10.5281/zenodo.3445428},
	url = {https://doi.org/10.5281/zenodo.2651640}
}

@article{fmriprep,
	title = {{FMRIP}rep: a robust preprocessing pipeline for functional {MRI}},
	author = {Esteban, Oscar and Markiewicz, Christopher and Blair, Ross W and Moodie, Craig and Isik, Ayse Ilkay and Aliaga, Asier Erramuzpe and Kent, James and Goncalves, Mathias and DuPre, Elizabeth and Snyder, Madeleine and others},
	journal = {Nature Methods},
	pages = {111–116},
	month = dec,
	year = 2019,
	publisher = {Nature Publishing Group},
	doi = {10.1038/s41592-018-0235-4},
	url = {https://doi.org/10.1038/s41592-018-0235-4},
}

@article{dsu,
	title = {High resolution three-dimensional brain atlas using an average magnetic resonance image of 40 adult C57Bl/6J mice},
	author = {A.E. Dorr and J.P. Lerch and S. Spring and N. Kabani and R.M. Henkelman},
	doi = {10.1016/j.neuroimage.2008.03.037},
	url = {https://doi.org/10.1016/j.neuroimage.2008.03.037},
	year = 2008,
	month = aug,
	publisher = {Elsevier {BV}},
	volume = {42},
	number = {1},
	pages = {60--69},
	journal = {{NeuroImage}},
}

@article{bold,
	doi = {10.1002/mrm.1910140108},
	url = {https://doi.org/10.1002/mrm.1910140108},
	year = 1990,
	month = apr,
	publisher = {Wiley},
	volume = {14},
	number = {1},
	pages = {68--78},
	author = {Seiji Ogawa and Tso-Ming Lee and Asha S. Nayak and Paul Glynn},
	title = {Oxygenation-sensitive contrast in magnetic resonance image of rodent brain at high magnetic fields},
	journal = {Magnetic Resonance in Medicine},
}

@article{cbv,
	title = {Investigation of the early response to rat forepaw stimulation},
	author = {John J.A. Marota and C. Ayata and Michael A. Moskowitz and Robert M. Weisskoff and Bruce R. Rosen and Joseph B. Mandeville},
	doi = {10.1002/(sici)1522-2594(199902)41:2<247::aid-mrm6>3.0.co;2-u},
	url = {https://doi.org/10.1002/(sici)1522-2594(199902)41:2<247::aid-mrm6>3.0.co;2-u},
	year = 1999,
	month = feb,
	publisher = {Wiley},
	volume = {41},
	number = {2},
	pages = {247--252},
	journal = {Magnetic Resonance in Medicine},
}

@inproceedings{statsmodels,
	title = {Statsmodels: {E}conometric and statistical modeling with {P}ython},
	author = {Seabold, Skipper and Perktold, Josef},
	booktitle = {9th Python in Science Conference},
	year = 2010,
	month = jun,
	url = {http://conference.scipy.org/proceedings/scipy2010/pdfs/seabold.pdf},
}

@misc{seaborn,
	author = {Michael Waskom and
		Olga Botvinnik and
		Drew O'Kane and
		Paul Hobson and
		Saulius Lukauskas and
		David C Gemperline and
		Tom Augspurger and
		Yaroslav Halchenko and
		John B. Cole and
		Jordi Warmenhoven and
		Julian de Ruiter and
		Cameron Pye and
		Stephan Hoyer and
		Jake Vanderplas and
		Santi Villalba and
		Gero Kunter and
		Eric Quintero and
		Pete Bachant and
		Marcel Martin and
		Kyle Meyer and
		Alistair Miles and
		Yoav Ram and
		Tal Yarkoni and
		Mike Lee Williams and
		Constantine Evans and
		Clark Fitzgerald and
		Brian and
		Chris Fonnesbeck and
		Antony Lee and
		Adel Qalieh},
	title = {Seaborn: v0.8.1},
	year = 2017,
	month = sep,
	doi = {10.5281/zenodo.883859},
	url = {https://doi.org/10.5281/zenodo.883859},
}

@article{scipy,
	title = {Python for Scientists and Engineers},
	author = {K. Jarrod Millman and Michael Aivazis},
	doi = {10.1109/mcse.2011.36},
	url = {https://doi.org/10.1109/mcse.2011.36},
	year = 2011,
	month = mar,
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {13},
	number = {2},
	pages = {9--12},
	journal = {Computing in Science {\&} Engineering},
}

@article{matplotlib,
	doi = {10.1109/mcse.2007.55},
	url = {https://doi.org/10.1109/mcse.2007.55},
	year = 2007,
	month = jun,
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {9},
	number = {3},
	pages = {90--95},
	author = {John D. Hunter},
	title = {Matplotlib: A 2{D} {G}raphics {E}nvironment},
	journal = {Computing in Science {\&} Engineering},
}

@InProceedings{pandas,
	title = { {D}ata {S}tructures for {S}tatistical {C}omputing in {P}ython },
	author = { Wes McKinney },
	booktitle = { Proceedings of the 9th Python in Science Conference },
	pages = { 51 - 56 },
	year = 2010,
	month = jun,
	editor = { St\'efan van der Walt and Jarrod Millman },
}

@article{Scott1979,
	title = {On optimal and data-based histograms},
	author = {David W. Scott},
	doi = {10.1093/biomet/66.3.605},
	url = {https://doi.org/10.1093/biomet/66.3.605},
	year = 1979,
	month = dec,
	publisher = {Oxford University Press ({OUP})},
	volume = {66},
	number = {3},
	pages = {605--610},
	journal = {Biometrika},
}

@article{long2000,
	title = {Using heteroscedasticity consistent standard errors in the linear regression model},
	author = {Long, J Scott and Ervin, Laurie H},
	journal = {The American Statistician},
	volume = {54},
	number = {3},
	pages = {217--224},
	year = 2000,
	month = aug,
	url = {https://www.jstor.org/stable/2685594},
	doi = {10.2307/2685594},
	publisher = {Taylor \& Francis},
}

@Article{bids,
	author = {Gorgolewski, Krzysztof J and Auer, Tibor and Calhoun, Vince D and Craddock, R Cameron and Das, Samir and Duff, Eugene P and Flandin, Guillaume and Ghosh, Satrajit S and Glatard, Tristan and Halchenko, Yaroslav O and others},
	title = {The brain imaging data structure, a format for organizing and describing outputs of neuroimaging experiments},
	journal = {Scientific Data},
	year = 2016,
	month = jun,
	volume = {3},
	pages = {160044},
	owner = {chymera},
	publisher = {Nature Publishing Group},
	timestamp = {2017.10.01},
	doi = {10.1038/sdata.2016.44},
	url = {https://doi.org/10.1038/sdata.2016.44},
}
