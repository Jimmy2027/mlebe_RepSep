\section{Methods}
It is of foremost importance that the complexity of MRI processing interfaces is manageable to their prospective users, such as biologists with only cursory programming experience.
One should, however, also be mindful that workflow transparency and reproducibility (a prerequisite for usage in scientific data analysis) are not compromised for trivial or superficial interactivity features. 
We thus follow  a set of design guidelines, stating that:
each pipeline is represented by a high-level function, whose parameters correspond to operator-understandable concepts (i.e. describe the operations performed, rather than the computational manner in which they are performed); 
pipeline functions are highly parameterized (so that users can change their function to a significant extent without needing to edit the constituent code) but include sane defaults;
and graphical or interactive interfaces are wholly avoided (as they impede reproducibility, encumber the dependency graph, and reduce the sustainability of the project).

\begin{figure*}[h]
	\begin{subfigure}{.67\textwidth}
		\centering
		\includedot[width=\textwidth]{data/generic}
		\vspace{.55em}
		\caption{1a}
		\label{fig:wfgg}
	\end{subfigure}%
	\begin{subfigure}{.33\textwidth}
		\centering
		\includedot[width=\textwidth]{data/legacy}
		\caption{1b}
		\label{fig:wfgl}
	\end{subfigure}
	\caption{
		Directed acyclic graphs depicting the two alternate workflow models and their constituent processing steps.
		The package correspondence of each processing node is appended in parantheses to the node name.
		The “utility” indication corresponds to nodes based on Python functions specific to the workflow, distributed alongside it, and dynamically wrapped via Nipype.
		The “extra\_interfaces” indication corresponds to nodes using explicitly defined Nipype-style interfaces, which are specific to the workflow and distributed alongside it.
		}
	\label{fig:wfg}
\end{figure*}

The language of choice for the pipelining interfaces is Python, owing to its Free and Open Source (FOSS) nature, readability, wealth of available libraries, ease of package management, and its large and dynamic developer community.
While pipeline functions are written in Python, we also provide automatically generated Command Line Interfaces (CLIs), for use directly with Bash.
These autogenerated CLIs ensure that features become available in Bash and Python synchronously, and pipelines behave identically regardless of the language in which they are invoked.

\subsection{Technologies}

Internally, the workflow functions make use of the Nipype \cite{nipype} package, which provides high-level management and execution features.
Via this package, functions provided by any other package can be encapsulated in a node (complete with error reporting and isolated re-execution support) and integrated into the directed workflow graph.
Paralellization can also be managed via a number of execution plugins, allowing excellent scalability.
Most importantly, Nipype can generate graph descriptor language (DOT) as well as visual representations (see \cref{fig:wfg}) of the workflows, which are suitable for operator inspection, graph theoretical analysis, and easier comparison between workflow variants.

Inside the framework constructed with Nipype we utilize basic MRI preprocessing functions from the FSL package \cite{fsl} and registration functions from the ANTs package \cite{ants}.
While there is theoretically no limit to the number of external packages usable with Nipype, we opted to constrain our choice as much as possible in order to minimize the dependency graph.
The choice of the ANTs package (in addition to FSL, which also provides registration functions) owes to the far higher parameterizability of its functions, which allow us to better adapt the registration to the brain images at hand.

Additionally we employ a number of functions specifically developed for our pipelines, which aid in more case-specific tasks, such as BIDS \cite{bids} input, and dummy scans management.

acyclic graph construction and reporting features, as well as jobs and resources management, and error reporting functions for the pipeline execution --- features which make it excellently suited to construct. 

