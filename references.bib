
@misc{noauthor_scikit-learn/scikit-learn_2020,
	title = {scikit-learn/scikit-learn},
	url = {https://github.com/scikit-learn/scikit-learn},
	abstract = {scikit-learn: machine learning in Python. Contribute to scikit-learn/scikit-learn development by creating an account on GitHub.},
	urldate = {2020-01-20},
	publisher = {scikit-learn},
	month = jan,
	year = {2020},
	note = {original-date: 2010-08-17T09:43:38Z},
	keywords = {data-analysis, data-science, machine-learning, python, statistics}
}

@article{sotiras_deformable_2013,
	title = {Deformable {Medical} {Image} {Registration}: {A} {Survey}},
	volume = {32},
	issn = {1558-254X},
	shorttitle = {Deformable {Medical} {Image} {Registration}},
	doi = {10.1109/TMI.2013.2265603},
	abstract = {Deformable image registration is a fundamental task in medical image processing. Among its most important applications, one may cite: 1) multi-modality fusion, where information acquired by different imaging devices or protocols is fused to facilitate diagnosis and treatment planning; 2) longitudinal studies, where temporal structural or anatomical changes are investigated; and 3) population modeling and statistical atlases used to study normal anatomical variability. In this paper, we attempt to give an overview of deformable registration methods, putting emphasis on the most recent advances in the domain. Additional emphasis has been given to techniques applied to medical images. In order to study image registration methods in depth, their main components are identified and studied independently. The most recent techniques are presented in a systematic fashion. The contribution of this paper is to provide an extensive account of registration techniques in a systematic manner.},
	number = {7},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Sotiras, Aristeidis and Davatzikos, Christos and Paragios, Nikos},
	month = jul,
	year = {2013},
	keywords = {Algorithms, Bibliographical review, Biomedical imaging, Computational modeling, Deformable models, Diagnostic Imaging, Humans, Image Processing, Computer-Assisted, Image registration, Linear programming, Mathematical model, Topology, deformable medical image registration, deformable registration, diagnosis, image fusion, image registration, imaging devices, information acquisition, medical image analysis, medical image processing, multimodality fusion, normal anatomical variability, patient treatment, population modeling, protocols, statistical analysis, statistical atlases, temporal anatomical changes, temporal structural changes, treatment planning},
	pages = {1153--1190}
}

@article{li_non-rigid_2017,
	title = {Non-rigid image registration using fully convolutional networks with deep self-supervision},
	url = {http://arxiv.org/abs/1709.00799},
	abstract = {We propose a novel non-rigid image registration algorithm that is built upon fully convolutional networks (FCNs) to optimize and learn spatial transformations between pairs of images to be registered. Different from most existing deep learning based image registration methods that learn spatial transformations from training data with known corresponding spatial transformations, our method directly estimates spatial transformations between pairs of images by maximizing an image-wise similarity metric between fixed and deformed moving images, similar to conventional image registration algorithms. At the same time, our method also learns FCNs for encoding the spatial transformations at the same spatial resolution of images to be registered, rather than learning coarse-grained spatial transformation information. The image registration is implemented in a multi-resolution image registration framework to jointly optimize and learn spatial transformations and FCNs at different resolutions with deep self-supervision through typical feedforward and backpropagation computation. Since our method simultaneously optimizes and learns spatial transformations for the image registration, our method can be directly used to register a pair of images, and the registration of a set of images is also a training procedure for FCNs so that the trained FCNs can be directly adopted to register new images by feedforward computation of the learned FCNs without any optimization. The proposed method has been evaluated for registering 3D structural brain magnetic resonance (MR) images and obtained better performance than state-of-the-art image registration algorithms.},
	urldate = {2020-01-20},
	journal = {arXiv:1709.00799 [cs]},
	author = {Li, Hongming and Fan, Yong},
	month = sep,
	year = {2017},
	note = {arXiv: 1709.00799},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{perez_effectiveness_2017,
	title = {The {Effectiveness} of {Data} {Augmentation} in {Image} {Classification} using {Deep} {Learning}},
	url = {http://arxiv.org/abs/1712.04621},
	abstract = {In this paper, we explore and compare multiple solutions to the problem of data augmentation in image classification. Previous work has demonstrated the effectiveness of data augmentation through simple techniques, such as cropping, rotating, and flipping input images. We artificially constrain our access to data to a small subset of the ImageNet dataset, and compare each data augmentation technique in turn. One of the more successful data augmentations strategies is the traditional transformations mentioned above. We also experiment with GANs to generate images of different styles. Finally, we propose a method to allow a neural net to learn augmentations that best improve the classifier, which we call neural augmentation. We discuss the successes and shortcomings of this method on various datasets.},
	urldate = {2020-01-19},
	journal = {arXiv:1712.04621 [cs]},
	author = {Perez, Luis and Wang, Jason},
	month = dec,
	year = {2017},
	note = {arXiv: 1712.04621},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{maintz_overview_nodate,
	title = {An {Overview} of {Medical} {Image} {Registration} {Methods}},
	abstract = {The purpose of this paper is to present an overview of existing medical image registration methods. These methods will be classiﬁed according to a model based on nine salient criteria, the main dichotomy of which is extrinsic versus intrinsic methods. The statistics of the classiﬁcation show deﬁnite trends in the evolving registration techniques, which will be discussed. At this moment, the bulk of interesting intrinsic methods is either based on segmented points or surfaces, or on techniques endeavoring to use the full information content of the images involved.},
	language = {en},
	author = {Maintz, J B Antoine and Viergever, Max A},
	pages = {22}
}

@article{geng_survey_2018,
	title = {Survey of recent progress in semantic image segmentation with {CNNs}},
	volume = {61},
	issn = {1674-733X, 1869-1919},
	url = {http://link.springer.com/10.1007/s11432-017-9189-6},
	doi = {10.1007/s11432-017-9189-6},
	abstract = {In recent years, convolutional neural networks (CNNs) are leading the way in many computer vision tasks, such as image classiﬁcation, object detection, and face recognition. In order to produce more reﬁned semantic image segmentation, we survey the powerful CNNs and novel elaborate layers, structures and strategies, especially including those that have achieved the state-of-the-art results on the Pascal VOC 2012 semantic segmentation challenge. Moreover, we discuss their diﬀerent working stages and various mechanisms to utilize the structural and contextual information in the image and feature spaces. Finally, combining some popular underlying referential methods in homologous problems, we propose several possible directions and approaches to incorporate existing eﬀective methods as components to enhance CNNs for the segmentation of speciﬁc semantic objects.},
	language = {en},
	number = {5},
	urldate = {2020-01-17},
	journal = {Science China Information Sciences},
	author = {Geng, Qichuan and Zhou, Zhong and Cao, Xiaochun},
	month = may,
	year = {2018},
	pages = {051101}
}

@article{madry_towards_2019,
	title = {Towards {Deep} {Learning} {Models} {Resistant} to {Adversarial} {Attacks}},
	url = {http://arxiv.org/abs/1706.06083},
	abstract = {Recent work has demonstrated that deep neural networks are vulnerable to adversarial examples---inputs that are almost indistinguishable from natural data and yet classified incorrectly by the network. In fact, some of the latest findings suggest that the existence of adversarial attacks may be an inherent weakness of deep learning models. To address this problem, we study the adversarial robustness of neural networks through the lens of robust optimization. This approach provides us with a broad and unifying view on much of the prior work on this topic. Its principled nature also enables us to identify methods for both training and attacking neural networks that are reliable and, in a certain sense, universal. In particular, they specify a concrete security guarantee that would protect against any adversary. These methods let us train networks with significantly improved resistance to a wide range of adversarial attacks. They also suggest the notion of security against a first-order adversary as a natural and broad security guarantee. We believe that robustness against such well-defined classes of adversaries is an important stepping stone towards fully resistant deep learning models. Code and pre-trained models are available at https://github.com/MadryLab/mnist\_challenge and https://github.com/MadryLab/cifar10\_challenge.},
	urldate = {2020-01-10},
	journal = {arXiv:1706.06083 [cs, stat]},
	author = {Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
	month = sep,
	year = {2019},
	note = {arXiv: 1706.06083},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning}
}

@article{ioanas_effects_nodate,
	title = {Effects of {Acute} and {Chronic} {Reuptake} {Inhibition} on {Optogenetically} {Induced} {Serotonergic} {Activity}},
	abstract = {The serotonergic system is widely implicated in aﬀect regulation, and a common target for psychopharmacological interventions. Selective Serotonin Reuptake Inhibitors (SSRIs) are the foremost drug class for treating depression, and also ﬁnd use in treating anxiety, phobia and other aﬀective disorders. However, the understanding of SSRI eﬀect mechanics is limited, thus hindering advancements in serotonergic manipulation. Moreover, high-power assays for longitudinal whole-brain interrogation of the serotonergic system are unavailable, yet such techniques are essential for evaluating diﬀerential eﬀects across projection areas. We present a longitudinal opto-fMRI assay suitable for exploring longitudinal drug treatment eﬀects on the mouse serotonergic system — within-subject and with sub-millimetre spatial resolution. This allowed segmentation of the brain into three longitudinal trajectory clusters, following two distinct patterns, which support the autoinhibition downregulation theory of SSRI eﬀects. We show that given the sensitivity of the assay, SSRI treatment produces no persistent eﬀects after treatment cessation in healthy subjects.},
	language = {en},
	author = {Ioanas, Horea-Ioan and Saab, Bechara John and Rudin, Markus},
	pages = {20}
}

@article{ioanas_whole-brain_nodate,
	title = {A {Whole}-{Brain} {Map} and {Assay} {Parameter} {Analysis} of {Mouse} {VTA} {Dopaminergic} {Activation}},
	abstract = {Ascending dopaminergic projections from neurons located in the Ventral Tegmental Area (VTA) are key to the etiology, dysfunction, and control of motivation, learning, and addiction. Due to evolutionary conservation of this nucleus and the extensive use of mice as disease models, establishing an assay for VTA dopaminergic signalling in the mouse brain is crucial for the translational investigation of neuronal function phenotypes of diseases and interventions. In this article we use optogenetic stimulation for targeted VTA dopaminergic neuron control, in combination with functional Magnetic Resonance Imaging (fMRI), a method widely used in human deep brain imaging. We present the ﬁrst whole-brain opto-fMRI map of VTA dopaminergic activation in the mouse, and show that dopaminergic system function is consistent with but diverges in a few key aspects from its structure. While the activation map predominantly includes and excludes target areas according to their relative projection densities (e.g. strong activation of the nucleus accumbens and low activation of the hippocampus), it also includes areas for which a structural connection is not well established (such as the dorsal striatum). We further detail assay variability with regard to multiple experimental parameters, including stimulation protocol and implant position, and provide detailed evidence-based recommendations for assay reuse.},
	language = {en},
	author = {Ioanas, Horea-Ioan and Saab, Bechara John and Rudin, Markus},
	pages = {19}
}

@misc{noauthor_multi-dimensional_nodate,
	title = {Multi-dimensional image processing (scipy.ndimage) — {SciPy} v1.4.1 {Reference} {Guide}},
	url = {https://docs.scipy.org/doc/scipy/reference/ndimage.html#morphology},
	urldate = {2020-01-07}
}

@misc{noauthor_multi-dimensional_nodate-1,
	title = {Multi-dimensional image processing (scipy.ndimage) — {SciPy} v1.4.1 {Reference} {Guide}},
	url = {https://docs.scipy.org/doc/scipy/reference/ndimage.html#morphology},
	urldate = {2020-01-07}
}

@misc{noauthor_neuroimaging_nodate,
	title = {Neuroimaging in {Python} — {NiBabel} 2.5.0 documentation},
	url = {https://nipy.org/nibabel/},
	urldate = {2020-01-07}
}

@article{milletari_v-net:_2016,
	title = {V-{Net}: {Fully} {Convolutional} {Neural} {Networks} for {Volumetric} {Medical} {Image} {Segmentation}},
	shorttitle = {V-{Net}},
	url = {http://arxiv.org/abs/1606.04797},
	abstract = {Convolutional Neural Networks (CNNs) have been recently employed to solve problems from both the computer vision and medical image analysis fields. Despite their popularity, most approaches are only able to process 2D images while most medical data used in clinical practice consists of 3D volumes. In this work we propose an approach to 3D image segmentation based on a volumetric, fully convolutional, neural network. Our CNN is trained end-to-end on MRI volumes depicting prostate, and learns to predict segmentation for the whole volume at once. We introduce a novel objective function, that we optimise during training, based on Dice coefficient. In this way we can deal with situations where there is a strong imbalance between the number of foreground and background voxels. To cope with the limited number of annotated volumes available for training, we augment the data applying random non-linear transformations and histogram matching. We show in our experimental evaluation that our approach achieves good performances on challenging test data while requiring only a fraction of the processing time needed by other previous methods.},
	urldate = {2020-01-05},
	journal = {arXiv:1606.04797 [cs]},
	author = {Milletari, Fausto and Navab, Nassir and Ahmadi, Seyed-Ahmad},
	month = jun,
	year = {2016},
	note = {arXiv: 1606.04797},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@misc{noauthor_ibt-fmi/samri_2019,
	title = {{IBT}-{FMI}/{SAMRI}},
	copyright = {GPL-3.0},
	url = {https://github.com/IBT-FMI/SAMRI},
	abstract = {Small Animal Magnetic Resonance Imaging via Python.},
	urldate = {2020-01-05},
	publisher = {Functional and Molecular Imaging @IBT(ETH/UZH)},
	month = dec,
	year = {2019},
	note = {original-date: 2015-04-27T00:26:08Z},
	keywords = {bids, biomedical, dwi, fmri, fsl, functional-connectivity, neuroimaging, registration, rodent, small-animals}
}

@misc{noauthor_callbacks_nodate,
	title = {Callbacks - {Keras} {Documentation}},
	url = {https://keras.io/callbacks/},
	urldate = {2020-01-05}
}

@article{srivastava_dropout:_nodate,
	title = {Dropout: {A} {Simple} {Way} to {Prevent} {Neural} {Networks} from {Overﬁtting}},
	abstract = {Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overﬁtting is a serious problem in such networks. Large networks are also slow to use, making it diﬃcult to deal with overﬁtting by combining the predictions of many diﬀerent large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of diﬀerent “thinned” networks. At test time, it is easy to approximate the eﬀect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This signiﬁcantly reduces overﬁtting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classiﬁcation and computational biology, obtaining state-of-the-art results on many benchmark data sets.},
	language = {en},
	author = {Srivastava, Nitish and Hinton, Geoﬀrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
	pages = {30}
}

@misc{zhixuhao_zhixuhao/unet_2020,
	title = {zhixuhao/unet},
	copyright = {MIT},
	url = {https://github.com/zhixuhao/unet},
	abstract = {unet for image segmentation. Contribute to zhixuhao/unet development by creating an account on GitHub.},
	urldate = {2020-01-05},
	author = {zhixuhao},
	month = jan,
	year = {2020},
	note = {original-date: 2017-04-06T01:58:15Z},
	keywords = {keras, segmentation, unet}
}

@article{ronneberger_u-net:_2015,
	title = {U-{Net}: {Convolutional} {Networks} for {Biomedical} {Image} {Segmentation}},
	shorttitle = {U-{Net}},
	url = {http://arxiv.org/abs/1505.04597},
	abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
	urldate = {2020-01-05},
	journal = {arXiv:1505.04597 [cs]},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	month = may,
	year = {2015},
	note = {arXiv: 1505.04597
version: 1},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@techreport{ioanas_optimized_2019,
	type = {preprint},
	title = {An {Optimized} {Registration} {Workflow} and {Standard} {Geometric} {Space} for {Small} {Animal} {Brain} {Imaging}},
	url = {http://biorxiv.org/lookup/doi/10.1101/619650},
	abstract = {The reliability of scientiﬁc results critically depends on reproducible and transparent data processing. Cross-subject and cross-study comparability of imaging data in general, and magnetic resonance imaging (MRI) data in particular, is contingent on the quality of registration to a standard reference space. In small animal MRI this is not adequately provided by currently used processing workﬂows, which utilize highlevel scripts optimized for human data, and adapt animal data to ﬁt the scripts, rather than vice-versa. In this fully reproducible article we showcase a generic workﬂow optimized for the mouse brain, alongside a standard reference space suited to harmonize data between analysis and operation. We present four separate metrics for automated quality control (QC), and a visualization method to aid operator inspection. Benchmarking this workﬂow against common legacy practices reveals that it performs more consistently, better preserves variance across subjects while minimizing variance across sessions, and improves both volume and smoothness conservation RMSE approximately 3-fold. We propose this open source workﬂow and the QC metrics as a new standard for small animal MRI registration, ensuring workﬂow robustness, data comparability, and region assignment validity, important criteria for the comparability of scientiﬁc results across experiments and centers.},
	language = {en},
	urldate = {2020-01-05},
	institution = {Neuroscience},
	author = {Ioanas, Horea-Ioan and Marks, Markus and Yanik, Mehmet Fatih and Rudin, Markus},
	month = apr,
	year = {2019},
	doi = {10.1101/619650}
}

@techreport{ioanas_optimized_2019-1,
	type = {preprint},
	title = {An {Optimized} {Registration} {Workflow} and {Standard} {Geometric} {Space} for {Small} {Animal} {Brain} {Imaging}},
	url = {http://biorxiv.org/lookup/doi/10.1101/619650},
	abstract = {The reliability of scientiﬁc results critically depends on reproducible and transparent data processing. Cross-subject and cross-study comparability of imaging data in general, and magnetic resonance imaging (MRI) data in particular, is contingent on the quality of registration to a standard reference space. In small animal MRI this is not adequately provided by currently used processing workﬂows, which utilize highlevel scripts optimized for human data, and adapt animal data to ﬁt the scripts, rather than vice-versa. In this fully reproducible article we showcase a generic workﬂow optimized for the mouse brain, alongside a standard reference space suited to harmonize data between analysis and operation. We present four separate metrics for automated quality control (QC), and a visualization method to aid operator inspection. Benchmarking this workﬂow against common legacy practices reveals that it performs more consistently, better preserves variance across subjects while minimizing variance across sessions, and improves both volume and smoothness conservation RMSE approximately 3-fold. We propose this open source workﬂow and the QC metrics as a new standard for small animal MRI registration, ensuring workﬂow robustness, data comparability, and region assignment validity, important criteria for the comparability of scientiﬁc results across experiments and centers.},
	language = {en},
	urldate = {2020-01-02},
	institution = {Neuroscience},
	author = {Ioanas, Horea-Ioan and Marks, Markus and Yanik, Mehmet Fatih and Rudin, Markus},
	month = apr,
	year = {2019},
	doi = {10.1101/619650}
}

@article{vartiainen_halo_2014,
	title = {Halo suppression in full-field x-ray {Zernike} phase contrast microscopy},
	volume = {39},
	issn = {0146-9592, 1539-4794},
	url = {https://www.osapublishing.org/abstract.cfm?URI=ol-39-6-1601},
	doi = {10.1364/OL.39.001601},
	language = {en},
	number = {6},
	urldate = {2019-11-21},
	journal = {Optics Letters},
	author = {Vartiainen, Ismo and Mokso, Rajmund and Stampanoni, Marco and David, Christian},
	month = mar,
	year = {2014},
	pages = {1601}
}

@article{pfeiffer_x-ray_2018,
	title = {X-ray ptychography},
	volume = {12},
	issn = {1749-4885, 1749-4893},
	url = {http://www.nature.com/articles/s41566-017-0072-5},
	doi = {10.1038/s41566-017-0072-5},
	language = {en},
	number = {1},
	urldate = {2019-11-20},
	journal = {Nature Photonics},
	author = {Pfeiffer, Franz},
	month = jan,
	year = {2018},
	pages = {9--17}
}

@article{pfeiffer_x-ray_2018-1,
	title = {X-ray ptychography},
	volume = {12},
	copyright = {2017 © Macmillan Publishers Limited, part of Springer Nature 2017},
	issn = {1749-4893},
	url = {https://www.nature.com/articles/s41566-017-0072-5},
	doi = {10.1038/s41566-017-0072-5},
	abstract = {This Review covers key advancements in X-ray ptychographic microscopy and tomography over the past ten years. Potential applications in the life and materials sciences, the latest concepts and future developments are also discussed.},
	language = {en},
	number = {1},
	urldate = {2019-11-19},
	journal = {Nature Photonics},
	author = {Pfeiffer, Franz},
	month = jan,
	year = {2018},
	pages = {9--17}
}

@article{athalye_obfuscated_2018,
	title = {Obfuscated {Gradients} {Give} a {False} {Sense} of {Security}: {Circumventing} {Defenses} to {Adversarial} {Examples}},
	shorttitle = {Obfuscated {Gradients} {Give} a {False} {Sense} of {Security}},
	url = {http://arxiv.org/abs/1802.00420},
	abstract = {We identify obfuscated gradients, a kind of gradient masking, as a phenomenon that leads to a false sense of security in defenses against adversarial examples. While defenses that cause obfuscated gradients appear to defeat iterative optimization-based attacks, we find defenses relying on this effect can be circumvented. We describe characteristic behaviors of defenses exhibiting the effect, and for each of the three types of obfuscated gradients we discover, we develop attack techniques to overcome it. In a case study, examining non-certified white-box-secure defenses at ICLR 2018, we find obfuscated gradients are a common occurrence, with 7 of 9 defenses relying on obfuscated gradients. Our new attacks successfully circumvent 6 completely, and 1 partially, in the original threat model each paper considers.},
	urldate = {2019-11-15},
	journal = {arXiv:1802.00420 [cs]},
	author = {Athalye, Anish and Carlini, Nicholas and Wagner, David},
	month = jul,
	year = {2018},
	note = {arXiv: 1802.00420},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security, Computer Science - Machine Learning}
}

@article{hannun_deep_2014,
	title = {Deep {Speech}: {Scaling} up end-to-end speech recognition},
	shorttitle = {Deep {Speech}},
	url = {http://arxiv.org/abs/1412.5567},
	abstract = {We present a state-of-the-art speech recognition system developed using end-to-end deep learning. Our architecture is significantly simpler than traditional speech systems, which rely on laboriously engineered processing pipelines; these traditional systems also tend to perform poorly when used in noisy environments. In contrast, our system does not need hand-designed components to model background noise, reverberation, or speaker variation, but instead directly learns a function that is robust to such effects. We do not need a phoneme dictionary, nor even the concept of a "phoneme." Key to our approach is a well-optimized RNN training system that uses multiple GPUs, as well as a set of novel data synthesis techniques that allow us to efficiently obtain a large amount of varied data for training. Our system, called Deep Speech, outperforms previously published results on the widely studied Switchboard Hub5'00, achieving 16.0\% error on the full test set. Deep Speech also handles challenging noisy environments better than widely used, state-of-the-art commercial speech systems.},
	urldate = {2019-11-09},
	journal = {arXiv:1412.5567 [cs]},
	author = {Hannun, Awni and Case, Carl and Casper, Jared and Catanzaro, Bryan and Diamos, Greg and Elsen, Erich and Prenger, Ryan and Satheesh, Sanjeev and Sengupta, Shubho and Coates, Adam and Ng, Andrew Y.},
	month = dec,
	year = {2014},
	note = {arXiv: 1412.5567},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing}
}

@article{tsipras_robustness_2019,
	title = {Robustness {May} {Be} at {Odds} with {Accuracy}},
	url = {http://arxiv.org/abs/1805.12152},
	abstract = {We show that there may exist an inherent tension between the goal of adversarial robustness and that of standard generalization. Speciﬁcally, training robust models may not only be more resource-consuming, but also lead to a reduction of standard accuracy. We demonstrate that this trade-off between the standard accuracy of a model and its robustness to adversarial perturbations provably exists in a fairly simple and natural setting. These ﬁndings also corroborate a similar phenomenon observed empirically in more complex settings. Further, we argue that this phenomenon is a consequence of robust classiﬁers learning fundamentally different feature representations than standard classiﬁers. These differences, in particular, seem to result in unexpected beneﬁts: the representations learned by robust models tend to align better with salient data characteristics and human perception.},
	language = {en},
	urldate = {2019-11-09},
	journal = {arXiv:1805.12152 [cs, stat]},
	author = {Tsipras, Dimitris and Santurkar, Shibani and Engstrom, Logan and Turner, Alexander and Madry, Aleksander},
	month = sep,
	year = {2019},
	note = {arXiv: 1805.12152},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning}
}

@article{madry_towards_2019-1,
	title = {Towards {Deep} {Learning} {Models} {Resistant} to {Adversarial} {Attacks}},
	url = {http://arxiv.org/abs/1706.06083},
	abstract = {Recent work has demonstrated that deep neural networks are vulnerable to adversarial examples---inputs that are almost indistinguishable from natural data and yet classified incorrectly by the network. In fact, some of the latest findings suggest that the existence of adversarial attacks may be an inherent weakness of deep learning models. To address this problem, we study the adversarial robustness of neural networks through the lens of robust optimization. This approach provides us with a broad and unifying view on much of the prior work on this topic. Its principled nature also enables us to identify methods for both training and attacking neural networks that are reliable and, in a certain sense, universal. In particular, they specify a concrete security guarantee that would protect against any adversary. These methods let us train networks with significantly improved resistance to a wide range of adversarial attacks. They also suggest the notion of security against a first-order adversary as a natural and broad security guarantee. We believe that robustness against such well-defined classes of adversaries is an important stepping stone towards fully resistant deep learning models. Code and pre-trained models are available at https://github.com/MadryLab/mnist\_challenge and https://github.com/MadryLab/cifar10\_challenge.},
	language = {en},
	urldate = {2019-11-09},
	journal = {arXiv:1706.06083 [cs, stat]},
	author = {Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
	month = sep,
	year = {2019},
	note = {arXiv: 1706.06083},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning}
}

@article{carlini_audio_2018,
	title = {Audio {Adversarial} {Examples}: {Targeted} {Attacks} on {Speech}-to-{Text}},
	shorttitle = {Audio {Adversarial} {Examples}},
	url = {http://arxiv.org/abs/1801.01944},
	abstract = {We construct targeted audio adversarial examples on automatic speech recognition. Given any audio waveform, we can produce another that is over 99.9\% similar, but transcribes as any phrase we choose (recognizing up to 50 characters per second of audio). We apply our white-box iterative optimization-based attack to Mozilla’s implementation DeepSpeech end-to-end, and show it has a 100\% success rate. The feasibility of this attack introduce a new domain to study adversarial examples.},
	language = {en},
	urldate = {2019-11-09},
	journal = {arXiv:1801.01944 [cs]},
	author = {Carlini, Nicholas and Wagner, David},
	month = mar,
	year = {2018},
	note = {arXiv: 1801.01944},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security, Computer Science - Machine Learning}
}

@article{modregger_grating-based_nodate,
	title = {Grating-{Based} {X}-{Ray} {Phase}- {Contrast} {Imaging}},
	language = {en},
	author = {Modregger, Peter and Pinzer, Bernd and Wang, Zhentian and Stampanoni, Marco},
	pages = {14}
}

@article{howells_introduction:_2009,
	title = {Introduction: {Special} issue on radiation damage},
	volume = {170},
	issn = {03682048},
	shorttitle = {Introduction},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0368204809000176},
	doi = {10.1016/j.elspec.2009.01.004},
	language = {en},
	number = {1-3},
	urldate = {2019-11-09},
	journal = {Journal of Electron Spectroscopy and Related Phenomena},
	author = {Howells, Malcolm R. and Hitchcock, Adam P. and Jacobsen, Chris J.},
	month = mar,
	year = {2009},
	pages = {1--3}
}

@article{fouras_past_2009,
	title = {The past, present, and future of x-ray technology for \textit{in vivo} imaging of function and form},
	volume = {105},
	issn = {0021-8979, 1089-7550},
	url = {http://aip.scitation.org/doi/10.1063/1.3115643},
	doi = {10.1063/1.3115643},
	language = {en},
	number = {10},
	urldate = {2019-11-09},
	journal = {Journal of Applied Physics},
	author = {Fouras, A. and Kitchen, M. J. and Dubsky, S. and Lewis, R. A. and Hooper, S. B. and Hourigan, K.},
	month = may,
	year = {2009},
	pages = {102009}
}

@article{paganin_simultaneous_2002,
	title = {Simultaneous phase and amplitude extraction from a single defocused image of a homogeneous object},
	volume = {206},
	issn = {0022-2720, 1365-2818},
	url = {http://doi.wiley.com/10.1046/j.1365-2818.2002.01010.x},
	doi = {10.1046/j.1365-2818.2002.01010.x},
	abstract = {We demonstrate simultaneous phase and amplitude extraction from a single defocused image of a homogeneous object. Subject to the assumptions explicitly stated in the derivation, the algorithm solves the twin-image problem of in-line holography and is capable of analysing data obtained using X-ray microscopy, electron microscopy, neutron microscopy or visible-light microscopy, especially as they relate to defocus and point projection methods. Our simple, robust, non-iterative and computationally efﬁcient method is applied to data obtained using an X-ray phase contrast ultramicroscope.},
	language = {en},
	number = {1},
	urldate = {2019-11-09},
	journal = {Journal of Microscopy},
	author = {Paganin, D. and Mayo, S. C. and Gureyev, T. E. and Miller, P. R. and Wilkins, S. W.},
	month = apr,
	year = {2002},
	pages = {33--40}
}

@article{meyer-ilse_high_2001,
	title = {High resolution protein localization using soft {X}-ray microscopy},
	volume = {201},
	issn = {0022-2720, 1365-2818},
	url = {http://doi.wiley.com/10.1046/j.1365-2818.2001.00845.x},
	doi = {10.1046/j.1365-2818.2001.00845.x},
	abstract = {Soft X-ray microscopes can be used to examine whole, hydrated cells up to 10 mm thick and produce images approaching 30 nm resolution. Since cells are imaged in the X-ray transmissive `water window', where organic material absorbs approximately an order of magnitude more strongly than water, chemical contrast enhancement agents are not required to view the distribution of cellular structures. Although living specimens cannot be examined, cells can be rapidly frozen at a precise moment in time and examined in a cryostage, revealing information that most closely approximates that in live cells. In this study, we used a transmission X-ray microscope at photon energies just below the oxygen edge (l  2.4 nm) to examine rapidly frozen mouse 3T3 cells and obtained excellent cellular morphology at better than 50 nm lateral resolution. These specimens are extremely stable, enabling multiple exposures with virtually no detectable damage to cell structures. We also show that silver-enhanced, immunogold labelling can be used to localize both cytoplasmic and nuclear proteins in whole, hydrated mammary epithelial cells at better than 50 nm resolution. The future use of X-ray tomography, along with improved zone plate lenses, will enable collection of better resolution (approaching 30 nm), three-dimensional information on the distribution of proteins in cells.},
	language = {en},
	number = {3},
	urldate = {2019-11-09},
	journal = {Journal of Microscopy},
	author = {Meyer-Ilse, W. and Hamamoto, D. and Nair, A. and Lelievre, S. A. and Denbeaux, G. and Johnson, L. and Pearson, A. L. and Yager, D. and Legros, M. A. and Larabell, C. A.},
	month = mar,
	year = {2001},
	pages = {395--403}
}

@article{busch_x-ray_nodate,
	title = {X-{RAY} {COMPUTED} {MICROTOMOGRAPHY} ({pCT}) {USING} {SYNCHROTRON} {RADIATION} ({SR})},
	language = {en},
	author = {Busch, Frank},
	pages = {37}
}

@article{xu_deepatlas:_2019,
	title = {{DeepAtlas}: {Joint} {Semi}-{Supervised} {Learning} of {Image} {Registration} and {Segmentation}},
	shorttitle = {{DeepAtlas}},
	url = {http://arxiv.org/abs/1904.08465},
	abstract = {Deep convolutional neural networks (CNNs) are state-of-the-art for semantic image segmentation, but typically require many labeled training samples. Obtaining 3D segmentations of medical images for supervised training is difficult and labor intensive. Motivated by classical approaches for joint segmentation and registration we therefore propose a deep learning framework that jointly learns networks for image registration and image segmentation. In contrast to previous work on deep unsupervised image registration, which showed the benefit of weak supervision via image segmentations, our approach can use existing segmentations when available and computes them via the segmentation network otherwise, thereby providing the same registration benefit. Conversely, segmentation network training benefits from the registration, which essentially provides a realistic form of data augmentation. Experiments on knee and brain 3D magnetic resonance (MR) images show that our approach achieves large simultaneous improvements of segmentation and registration accuracy (over independently trained networks) and allows training high-quality models with very limited training data. Specifically, in a one-shot-scenario (with only one manually labeled image) our approach increases Dice scores (\%) over an unsupervised registration network by 2.7 and 1.8 on the knee and brain images respectively.},
	urldate = {2019-11-09},
	journal = {arXiv:1904.08465 [cs]},
	author = {Xu, Zhenlin and Niethammer, Marc},
	month = jul,
	year = {2019},
	note = {arXiv: 1904.08465},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{zhou_normalization_2019,
	title = {Normalization in {Training} {U}-{Net} for 2D {Biomedical} {Semantic} {Segmentation}},
	url = {http://arxiv.org/abs/1809.03783},
	abstract = {2D biomedical semantic segmentation is important for robotic vision in surgery. Segmentation methods based on Deep Convolutional Neural Network (DCNN) can out-perform conventional methods in terms of both accuracy and levels of automation. One common issue in training a DCNN for biomedical semantic segmentation is the internal covariate shift where the training of convolutional kernels is encumbered by the distribution change of input features, hence both the training speed and performance are decreased. Batch Normalization (BN) is the first proposed method for addressing internal covariate shift and is widely used. Instance Normalization (IN) and Layer Normalization (LN) have also been proposed. Group Normalization (GN) is proposed more recently and has not yet been applied to 2D biomedical semantic segmentation, however, no specific validations on GN were given. Most DCNNs for biomedical semantic segmentation adopt BN as the normalization method by default, without reviewing its performance. In this paper, four normalization methods - BN, IN, LN and GN are compared in details, specifically for 2D biomedical semantic segmentation. U-Net is adopted as the basic DCNN structure. Three datasets regarding the Right Ventricle (RV), aorta, and Left Ventricle (LV) are used for the validation. The results show that detailed subdivision of the feature map, i.e. GN with a large group number or IN, achieves higher accuracy. This accuracy improvement mainly comes from better model generalization. Codes are uploaded and maintained at Xiao-Yun Zhou's Github.},
	urldate = {2019-11-09},
	journal = {arXiv:1809.03783 [cs]},
	author = {Zhou, Xiao-Yun and Yang, Guang-Zhong},
	month = jan,
	year = {2019},
	note = {arXiv: 1809.03783},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{wakonig_x-ray_2019,
	title = {X-ray {Fourier} ptychography},
	volume = {5},
	issn = {2375-2548},
	url = {http://advances.sciencemag.org/lookup/doi/10.1126/sciadv.aav0282},
	doi = {10.1126/sciadv.aav0282},
	abstract = {To a large extent, the performance of imaging systems is determined by their objectives, which affect properties as varied as collection efficiency, resolving power, and image distortions. Such limitations can be addressed by so-called aperture synthesis, a technique used, for instance, in radar, astronomy, and, increasingly, microscopy. Here, we apply such techniques to x-ray imaging and demonstrate how Fourier ptychography can be used at transmission x-ray microscopes to increase resolution, provide quantitative absorption and phase contrast, and allow for corrections of lens aberrations. We anticipate that such methods will find common and frequent applications, alleviating a number of limitations imposed by x-ray optical elements, offering an alternative approach to phase contrast imaging, and providing novel opportunities to mitigate radiation damage.},
	language = {en},
	number = {2},
	urldate = {2019-11-09},
	journal = {Science Advances},
	author = {Wakonig, Klaus and Diaz, Ana and Bonnin, Anne and Stampanoni, Marco and Bergamaschi, Anna and Ihli, Johannes and Guizar-Sicairos, Manuel and Menzel, Andreas},
	month = feb,
	year = {2019},
	pages = {eaav0282}
}

@article{patera_non-rigid_2018,
	title = {A non-rigid registration method for the analysis of local deformations in the wood cell wall},
	volume = {4},
	issn = {2198-0926},
	url = {https://ascimaging.springeropen.com/articles/10.1186/s40679-018-0050-0},
	doi = {10.1186/s40679-018-0050-0},
	abstract = {This paper concerns the problem of wood cellular structure image registration. Given the large variability of wood geometry and the important changes in the cellular organization due to moisture sorption, an affine-based image registration technique is not exhaustive to describe the overall hygro-mechanical behaviour of wood at micrometre scales. Additionally, free tools currently available for non-rigid image registration are not suitable for quantifying the structural deformations of complex hierarchical materials such as wood, leading to errors due to misalignment. In this paper, we adapt an existing non-rigid registration model based on B-spline functions to our case study. The so-modified algorithm combines the concept of feature recognition within specific regions locally distributed in the material with an optimization problem. Results show that the method is able to quantify local deformations induced by moisture changes in tomographic images of wood cell wall with high accuracy. The local deformations provide new important insights in characterizing the swelling behaviour of wood at the cell wall level.},
	language = {en},
	number = {1},
	urldate = {2019-11-09},
	journal = {Advanced Structural and Chemical Imaging},
	author = {Patera, Alessandra and Carl, Stephan and Stampanoni, Marco and Derome, Dominique and Carmeliet, Jan},
	month = dec,
	year = {2018},
	pages = {1}
}

@misc{noauthor_zotero_nodate,
	title = {Zotero {\textbar} {Your} personal research assistant},
	url = {https://www.zotero.org/start},
	urldate = {2019-11-09}
}